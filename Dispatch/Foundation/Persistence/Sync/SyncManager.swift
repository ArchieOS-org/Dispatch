//
//  SyncManager.swift
//  Dispatch
//
//  Created for Phase 1.3: SyncManager Service
//  Orchestrates bidirectional sync between SwiftData and Supabase
//

import Combine
import CryptoKit
import Foundation
import Network
import PostgREST
import Supabase
import SwiftData

// MARK: - SyncRunMode

enum SyncRunMode: Sendable {
  case live
  case preview
  case test // Deterministic mode: no network, timers, or side effects
}

// MARK: - SyncManager

@MainActor
final class SyncManager: ObservableObject {

  // MARK: Lifecycle

  init(mode: SyncRunMode = .live) {
    self.mode = mode

    // Only load expensive state in live mode
    if mode == .live {
      // Restore persisted lastSyncTime
      lastSyncTime = UserDefaults.standard.object(forKey: Self.lastSyncTimeKey) as? Date
    } else {
      lastSyncTime = nil
    }

    debugLog.log("SyncManager singleton initialized (mode: \(mode))", category: .sync)
    if mode == .live {
      debugLog.log("  Restored lastSyncTime: \(lastSyncTime?.description ?? "nil")", category: .sync)
    }
  }

  deinit {
    // Strict Jobs Standard: NO calls to actor-isolated state (isShutdown) here.
    // Lifecycle enforcement belongs in tests.
    // Only safe, non-isolated reads allowed.
  }

  // MARK: Internal

  typealias RunMode = SyncRunMode

  static let shared = SyncManager()

  static let lastSyncTimeKey = "dispatch.lastSyncTime"
  static let lastSyncListingTypesKey = "dispatch.lastSyncListingTypes"
  static let lastSyncActivityTemplatesKey = "dispatch.lastSyncActivityTemplates"
  static let lastSyncNotesKey = "dispatch.lastSyncNotes"

  nonisolated let mode: RunMode
  /// Internal counter for verifying preview isolation
  var _telemetry_syncRequests = 0

  @Published private(set) var isSyncing = false
  @Published private(set) var isListingConfigReady = false // UI gate for AddListingSheet
  @Published private(set) var syncError: Error?
  @Published private(set) var syncStatus = SyncStatus.idle
  @Published var currentUser: User? // The actual profile object, for UI state

  /// User-facing error message when syncStatus is .error
  @Published private(set) var lastSyncErrorMessage: String?

  /// Sync run counter for correlating claim actions with sync results
  @Published private(set) var syncRunId = 0

  var realtimeChannel: RealtimeChannelV2?
  var broadcastChannel: RealtimeChannelV2?
  /// Explicit, named properties for structured concurrency.
  /// Strong capture + explicit shutdown() ensures deterministic lifecycle.

  /// Core Tasks
  var syncLoopTask: Task<Void, Never>?
  // Status & Broadcast
  var statusTask: Task<Void, Never>?
  var broadcastTask: Task<Void, Never>?

  // Per-Table Listener Groups
  var startBroadcastListeningTask: Task<Void, Never>? // Tracks the setup task
  var tasksSubscriptionTask: Task<Void, Never>?
  var activitiesSubscriptionTask: Task<Void, Never>?
  var listingsSubscriptionTask: Task<Void, Never>?
  var usersSubscriptionTask: Task<Void, Never>?
  var claimEventsSubscriptionTask: Task<Void, Never>?
  var notesSubscriptionTask: Task<Void, Never>?

  #if DEBUG
  /// For verifying shutdown logic without side effects
  var debugHangingTask: Task<Void, Never>?
  #endif

  #if DEBUG
  /// Allows testing the coalescing loop logic without actual network syncs
  var _simulateCoalescingInTest = false
  #endif

  @Published private(set) var lastSyncTime: Date? {
    didSet {
      // Jobs Standard: Isolated Persistance
      // Only persist in .live mode. Tests must effectively run in memory.
      if mode == .live {
        if let time = lastSyncTime {
          UserDefaults.standard.set(time, forKey: Self.lastSyncTimeKey)
        } else {
          UserDefaults.standard.removeObject(forKey: Self.lastSyncTimeKey)
        }
      }
    }
  }

  /// Last Sync for Notes (Incremental)
  @Published private(set) var lastSyncNotes: Date? {
    didSet {
      if mode == .live {
        if let time = lastSyncNotes {
          UserDefaults.standard.set(time, forKey: Self.lastSyncNotesKey)
        } else {
          UserDefaults.standard.removeObject(forKey: Self.lastSyncNotesKey)
        }
      }
    }
  }

  @Published var currentUserID: UUID? { // Set when authenticated
    didSet {
      // Attempt to load user from local DB immediately when ID changes
      if let id = currentUserID {
        fetchCurrentUser(id: id)
      } else {
        currentUser = nil
      }
    }
  }

  #if DEBUG
  /// Test Hook: Allows setting lastSyncTime in tests without triggering persistence side effects
  /// or violating read-only visibility.
  func _debugSetLastSyncTime(_ date: Date?) {
    lastSyncTime = date
  }
  #endif
  func configure(with container: ModelContainer) {
    debugLog.log("configure() called", category: .sync)
    modelContainer = container
    debugLog.log("  modelContainer set: \(container)", category: .sync)
  }

  /// Updates the current authenticated user and triggers sync logic
  func updateCurrentUser(_ userId: UUID?) {
    debugLog.log("updateCurrentUser() called: \(userId?.uuidString ?? "nil")", category: .sync)
    currentUserID = userId
  }

  /// Coalescing sync request - replaces "fire and forget" tasks with a single consumer.
  /// Guaranteed to run on MainActor.
  func requestSync() {
    // Strict Preview Guard
    if mode == .preview {
      _telemetry_syncRequests += 1
      return
    }

    // Test Mode Guard
    // In .test, syncs must be manually triggered via `await sync()`
    // UNLESS we are specifically verifying the coalescing logic.
    if mode == .test {
      #if DEBUG
      if !_simulateCoalescingInTest {
        return
      }
      #else
      return
      #endif
    }

    // 1. Set Flag
    syncRequested = true

    // 2. Ensure Loop Exists
    if syncLoopTask == nil {
      debugLog.log("Starting sync loop...", category: .sync)
      syncLoopTask = Task {
        // Guaranteed Nil-ing: Clear property on exit (finish or cancel)
        // RULE: cleanup at bottom of scope via MainActor.run. NO defer watcher.

        // Drain Loop
        while !Task.isCancelled {
          // Check logic on MainActor
          let shouldRun = await MainActor.run {
            if self.syncRequested {
              self.syncRequested = false
              return true
            }
            return false
          }

          if !shouldRun { break }

          // Do the work (holds self strongly during execution)
          await self.sync()
        }

        // Explicit Cleanup: Must happen on MainActor
        await MainActor.run {
          self.syncLoopTask = nil
          debugLog.log("Sync loop exited.", category: .sync)
        }
      }
    } else {
      debugLog.log("Sync request coalesced into existing loop.", category: .sync)
    }
  }

  /// Resets lastSyncTime to nil, forcing the next sync to run full reconciliation.
  /// Use this to manually trigger orphan cleanup when you suspect local/remote mismatch.
  func resetLastSyncTime() {
    debugLog.log("resetLastSyncTime() called - next sync will run FULL RECONCILIATION", category: .sync)
    lastSyncTime = nil
  }

  /// Performs a full sync with orphan reconciliation, regardless of lastSyncTime.
  /// This is useful for debugging or when you know data has been deleted on the server.
  func fullSync() async {
    debugLog.log("fullSync() called - forcing full reconciliation", category: .sync)
    let savedLastSyncTime = lastSyncTime
    lastSyncTime = nil // Temporarily reset to force reconciliation
    await sync()
    // Note: sync() will set a new lastSyncTime on success, so we don't restore savedLastSyncTime
    _ = savedLastSyncTime // Silence unused variable warning
  }

  /// Retry syncing a single failed entity. This triggers a full sync but ensures
  /// the entity's state is reset to .pending first (done in markPending).
  /// The normal sync flow will then pick it up.
  func retrySync() async {
    await sync()
  }

  /// Retry syncing a specific TaskItem
  func retryTask(_ task: TaskItem) async {
    debugLog.log("retryTask() called for \(task.id)", category: .sync)
    task.syncState = .pending
    task.lastSyncError = nil
    await sync()
  }

  /// Retry syncing a specific Activity
  func retryActivity(_ activity: Activity) async {
    debugLog.log("retryActivity() called for \(activity.id)", category: .sync)
    activity.syncState = .pending
    activity.lastSyncError = nil
    await sync()
  }

  /// Retry syncing a specific Listing
  func retryListing(_ listing: Listing) async {
    debugLog.log("retryListing() called for \(listing.id)", category: .sync)
    listing.syncState = .pending
    listing.lastSyncError = nil
    await sync()
  }

  /// Retry syncing a specific ClaimEvent
  func retryClaimEvent(_ claimEvent: ClaimEvent) async {
    debugLog.log("retryClaimEvent() called for \(claimEvent.id)", category: .sync)
    claimEvent.syncState = .pending
    claimEvent.lastSyncError = nil
    await sync()
  }

  func sync() async {
    // Increment sync run ID for correlating claim actions with sync results
    syncRunId &+= 1
    let runId = syncRunId

    #if DEBUG
    if _simulateCoalescingInTest {
      debugLog.log("‚ö°Ô∏è [TEST] Simulated sync() runId: \(runId)", category: .sync)
      // Simulate work
      try? await Task.sleep(nanoseconds: 50_000_000) // 50ms
      return
    }
    #endif

    debugLog.log("========== sync() STARTED (runId: \(runId)) ==========", category: .sync)
    debugLog.log("  isAuthenticated: \(isAuthenticated)", category: .sync)
    debugLog.log("  isSyncing: \(isSyncing)", category: .sync)
    debugLog.log("  currentUserID: \(currentUserID?.uuidString ?? "nil")", category: .sync)
    debugLog.log("  lastSyncTime: \(lastSyncTime?.description ?? "nil")", category: .sync)

    // Redundant guide but safe
    if mode == .preview {
      return
    }

    guard isAuthenticated else {
      debugLog.log("SKIPPING sync - not authenticated", category: .sync)
      if syncRunId == runId {
        syncStatus = .idle
      }
      return
    }

    guard let container = modelContainer else {
      debugLog.log("SKIPPING sync - no modelContainer", category: .sync)
      return
    }

    // Coalescing loop pattern: queue sync requests instead of cancelling in-flight requests
    // If already syncing, set flag and return - the active sync will run another pass when done
    if isSyncing {
      syncRequestedDuringSync = true
      debugLog.log("QUEUED sync - will run after current sync completes", category: .sync)
      return
    }

    var runAgain: Bool

    repeat {
      isSyncing = true
      syncRequestedDuringSync = false
      syncStatus = .syncing
      syncError = nil
      debugLog.startTiming("Full Sync")

      do {
        // CRITICAL FIX: Use mainContext instead of creating a new ModelContext
        // This ensures we see entities created in other parts of the app (e.g., SyncTestHarness)
        // Previously: let context = ModelContext(container) - this created an isolated context
        // that couldn't see unsaved entities from the UI's @Environment(\.modelContext)
        let context = container.mainContext
        debugLog.log("Using container.mainContext (shared context)", category: .sync)

        debugLog.startTiming("syncDown")
        try await syncDown(context: context)
        debugLog.endTiming("syncDown")

        debugLog.startTiming("syncUp")
        try await syncUp(context: context)
        debugLog.endTiming("syncUp")

        debugLog.log("Saving ModelContext...", category: .sync)
        try context.save()
        debugLog.log("ModelContext saved successfully", category: .sync)

        let syncTimestamp = Date()
        lastSyncTime = syncTimestamp
        // Only update status if this is still the current sync run
        if syncRunId == runId {
          syncStatus = .ok(Date())
          lastSyncErrorMessage = nil
        }
        debugLog.endTiming("Full Sync")
        debugLog.log("========== sync() COMPLETED at \(syncTimestamp) ==========", category: .sync)
      } catch {
        debugLog.endTiming("Full Sync")
        debugLog.error("========== sync() FAILED ==========", error: error)
        syncError = error
        // Only update status if this is still the current sync run
        if syncRunId == runId {
          syncStatus = .error
          lastSyncErrorMessage = userFacingMessage(for: error)
        }
      }

      isSyncing = false
      runAgain = syncRequestedDuringSync
      syncRequestedDuringSync = false

      if runAgain {
        debugLog.log("Running queued sync...", category: .sync)
      }
    } while runAgain
  }

  /// Delete a task by ID from local SwiftData (used by cleanup and realtime DELETE handling)
  func deleteLocalTask(id: UUID, context: ModelContext) throws -> Bool {
    let descriptor = FetchDescriptor<TaskItem>(predicate: #Predicate { $0.id == id })
    guard let task = try context.fetch(descriptor).first else {
      debugLog.log("deleteLocalTask: Task \(id) not found locally", category: .sync)
      return false
    }
    debugLog.log("deleteLocalTask: Deleting task \(id) - \(task.title)", category: .sync)
    context.delete(task)
    return true
  }

  /// Delete an activity by ID from local SwiftData
  func deleteLocalActivity(id: UUID, context: ModelContext) throws -> Bool {
    let descriptor = FetchDescriptor<Activity>(predicate: #Predicate { $0.id == id })
    guard let activity = try context.fetch(descriptor).first else {
      debugLog.log("deleteLocalActivity: Activity \(id) not found locally", category: .sync)
      return false
    }
    debugLog.log("deleteLocalActivity: Deleting activity \(id) - \(activity.title)", category: .sync)
    context.delete(activity)
    return true
  }

  /// Delete a listing by ID from local SwiftData
  func deleteLocalListing(id: UUID, context: ModelContext) throws -> Bool {
    let descriptor = FetchDescriptor<Listing>(predicate: #Predicate { $0.id == id })
    guard let listing = try context.fetch(descriptor).first else {
      debugLog.log("deleteLocalListing: Listing \(id) not found locally", category: .sync)
      return false
    }
    debugLog.log("deleteLocalListing: Deleting listing \(id) - \(listing.address)", category: .sync)
    context.delete(listing)
    return true
  }

  /// Delete a user by ID from local SwiftData
  func deleteLocalUser(id: UUID, context: ModelContext) throws -> Bool {
    let descriptor = FetchDescriptor<User>(predicate: #Predicate { $0.id == id })
    guard let user = try context.fetch(descriptor).first else {
      debugLog.log("deleteLocalUser: User \(id) not found locally", category: .sync)
      return false
    }
    debugLog.log("deleteLocalUser: Deleting user \(id) - \(user.name)", category: .sync)
    context.delete(user)
    return true
  }

  /// Delete a claim event by ID from local SwiftData
  func deleteLocalClaimEvent(id: UUID, context: ModelContext) throws -> Bool {
    let descriptor = FetchDescriptor<ClaimEvent>(predicate: #Predicate { $0.id == id })
    guard let claimEvent = try context.fetch(descriptor).first else {
      debugLog.log("deleteLocalClaimEvent: ClaimEvent \(id) not found locally", category: .sync)
      return false
    }
    debugLog.log("deleteLocalClaimEvent: Deleting claim event \(id)", category: .sync)
    context.delete(claimEvent)
    return true
  }

  /// Delete a note by ID from local SwiftData
  func deleteLocalNote(id: UUID, context: ModelContext) throws -> Bool {
    let descriptor = FetchDescriptor<Note>(predicate: #Predicate { $0.id == id })
    guard let note = try context.fetch(descriptor).first else {
      debugLog.log("deleteLocalNote: Note \(id) not found locally", category: .sync)
      return false
    }
    debugLog.log("deleteLocalNote: Deleting note \(id)", category: .sync)
    context.delete(note)
    return true
  }

  /// Establishes relationship between a listing and its owner (User)
  /// - Parameters:
  ///   - listing: The listing entity
  ///   - ownerId: The UUID of the owner (from owned_by)
  ///   - context: SwiftData context
  func establishListingOwnerRelationship(listing: Listing, ownerId: UUID, context: ModelContext) throws {
    // If already linked correctly, exit early
    if let currentOwner = listing.owner, currentOwner.id == ownerId {
      // Already correct
      return
    }

    let userDescriptor = FetchDescriptor<User>(predicate: #Predicate { $0.id == ownerId })
    if let user = try context.fetch(userDescriptor).first {
      // Only log if we are actually changing it (to avoid noise)
      if listing.owner == nil {
        debugLog.log("      Linking listing \(listing.address) to owner \(user.name)", category: .sync)
      }
      listing.owner = user
    } else {
      // Use this sporadically? Or only when it fails?
      // In initial sync, user might not be there yet. That's expected.
    }
  }

  /// Reconciles missing Listing.owner relationships by linking them to available Users
  /// Called at the end of syncDown to ensure order-independence
  func reconcileListingRelationships(context: ModelContext) throws {
    debugLog.log("reconcileListingRelationships() - Starting...", category: .sync)

    // 1. Fetch all 'active' listings that are missing an owner
    // We exclude deleted listings to avoid churning on history
    let descriptor = FetchDescriptor<Listing>(
      predicate: #Predicate { $0.owner == nil && $0.deletedAt == nil }
    )
    let orphans = try context.fetch(descriptor)

    guard !orphans.isEmpty else {
      debugLog.log("  No active orphan listings found. Reconciliation complete.", category: .sync)
      return
    }

    debugLog.log("  Found \(orphans.count) orphan listings. Batch resolving...", category: .sync)

    // 2. Batch fetch ALL users into a dictionary for O(1) lookup
    // Efficiency: <1s for <10k users. Access by UUID is fast.
    let userDescriptor = FetchDescriptor<User>()
    let allUsers = try context.fetch(userDescriptor)
    let usersById = Dictionary(uniqueKeysWithValues: allUsers.map { ($0.id, $0) })

    // 3. Resolve
    var repairedCount = 0

    for listing in orphans {
      if let user = usersById[listing.ownedBy] {
        listing.owner = user
        repairedCount += 1
      }
    }

    debugLog.log("  Reconciliation summary: Found \(orphans.count) orphans, Repaired \(repairedCount)", category: .sync)
  }

  func startListening() async {
    // Strict Preview/Test Guard
    if mode == .preview || mode == .test {
      return
    }

    debugLog.log("", category: .realtime)
    debugLog.log("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó", category: .realtime)
    debugLog.log("‚ïë           startListening() CALLED                          ‚ïë", category: .realtime)
    debugLog.log("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù", category: .realtime)

    guard isAuthenticated else {
      debugLog.log("SKIPPING startListening - not authenticated", category: .realtime)
      return
    }
    guard !isListening else {
      debugLog.log("SKIPPING startListening - already listening", category: .realtime)
      return
    }
    guard modelContainer != nil else {
      debugLog.log("SKIPPING startListening - no modelContainer", category: .realtime)
      return
    }

    // 1. Create Channel
    let channelName = "dispatch-sync"
    let channel = supabase.realtimeV2.channel(channelName)

    // 2. Configure Streams (Insert/Update/Delete) for each table
    // --- TASKS ---
    let tasksInserts = channel.postgresChange(InsertAction.self, schema: "public", table: "tasks")
    let tasksUpdates = channel.postgresChange(UpdateAction.self, schema: "public", table: "tasks")
    let tasksDeletes = channel.postgresChange(DeleteAction.self, schema: "public", table: "tasks")

    // --- ACTIVITIES ---
    let actInserts = channel.postgresChange(InsertAction.self, schema: "public", table: "activities")
    let actUpdates = channel.postgresChange(UpdateAction.self, schema: "public", table: "activities")
    let actDeletes = channel.postgresChange(DeleteAction.self, schema: "public", table: "activities")

    // --- LISTINGS ---
    let listInserts = channel.postgresChange(InsertAction.self, schema: "public", table: "listings")
    let listUpdates = channel.postgresChange(UpdateAction.self, schema: "public", table: "listings")
    let listDeletes = channel.postgresChange(DeleteAction.self, schema: "public", table: "listings")

    // --- USERS ---
    let usersInserts = channel.postgresChange(InsertAction.self, schema: "public", table: "users")
    let usersUpdates = channel.postgresChange(UpdateAction.self, schema: "public", table: "users")
    let usersDeletes = channel.postgresChange(DeleteAction.self, schema: "public", table: "users")

    // --- CLAIM EVENTS ---
    let claimInserts = channel.postgresChange(InsertAction.self, schema: "public", table: "claim_events")
    let claimUpdates = channel.postgresChange(UpdateAction.self, schema: "public", table: "claim_events")
    let claimDeletes = channel.postgresChange(DeleteAction.self, schema: "public", table: "claim_events")

    // --- NOTES ---
    let noteInserts = channel.postgresChange(InsertAction.self, schema: "public", table: "notes")
    let noteUpdates = channel.postgresChange(UpdateAction.self, schema: "public", table: "notes")
    let noteDeletes = channel.postgresChange(DeleteAction.self, schema: "public", table: "notes")

    // PHASE A: Prepare (Create channel + stream refs, no global state writes)
    // Subscribe to channel
    do {
      try await channel.subscribeWithError()
    } catch {
      debugLog.error("‚ùå Realtime subscribe failed", error: error)
      await shutdown()
      return
    }

    // PHASE B: Publish (Commit state + spawn tasks)
    // Only set this AFTER successful subscribe
    realtimeChannel = channel
    isListening = true

    // PHASE C: Spawn Consumption Tasks
    // Now it is safe to spawn tasks because we are committed.

    statusTask = Task {
      for await status in channel.statusChange {
        if Task.isCancelled { return }
        debugLog.log("Realtime Status: \(status)", category: .realtime)
        await MainActor.run {
          self.syncStatus = self.mapRealtimeStatus(status)
        }
      }
    }

    tasksSubscriptionTask = Task {
      await withTaskGroup(of: Void.self) { group in
        group.addTask { for await e in tasksInserts { if Task.isCancelled { return }
          await self.handleTaskInsert(e)
        } }
        group.addTask { for await e in tasksUpdates { if Task.isCancelled { return }
          await self.handleTaskUpdate(e)
        } }
        group.addTask { for await e in tasksDeletes { if Task.isCancelled { return }
          await self.handleTaskDelete(e)
        } }
      }
    }

    activitiesSubscriptionTask = Task {
      await withTaskGroup(of: Void.self) { group in
        group.addTask { for await e in actInserts { if Task.isCancelled { return }
          await self.handleActivityInsert(e)
        } }
        group.addTask { for await e in actUpdates { if Task.isCancelled { return }
          await self.handleActivityUpdate(e)
        } }
        group.addTask { for await e in actDeletes { if Task.isCancelled { return }
          await self.handleActivityDelete(e)
        } }
      }
    }

    listingsSubscriptionTask = Task {
      await withTaskGroup(of: Void.self) { group in
        group.addTask { for await e in listInserts { if Task.isCancelled { return }
          await self.handleListingInsert(e)
        } }
        group.addTask { for await e in listUpdates { if Task.isCancelled { return }
          await self.handleListingUpdate(e)
        } }
        group.addTask { for await e in listDeletes { if Task.isCancelled { return }
          await self.handleListingDelete(e)
        } }
      }
    }

    usersSubscriptionTask = Task {
      await withTaskGroup(of: Void.self) { group in
        group.addTask {
          for await e in usersInserts {
            if Task.isCancelled { return }
            await self.handleUserInsert(e)
          }
        }
        group.addTask {
          for await e in usersUpdates {
            if Task.isCancelled { return }
            await self.handleUserUpdate(e)
          }
        }
        group.addTask {
          for await e in usersDeletes {
            if Task.isCancelled { return }
            await self.handleUserDelete(e)
          }
        }
      }
    }

    claimEventsSubscriptionTask = Task {
      await withTaskGroup(of: Void.self) { group in
        group.addTask {
          for await e in claimInserts {
            if Task.isCancelled { return }
            await self.handleClaimEventInsert(e)
          }
        }
        group.addTask {
          for await e in claimUpdates {
            if Task.isCancelled { return }
            await self.handleClaimEventUpdate(e)
          }
        }
        group.addTask {
          for await e in claimDeletes {
            if Task.isCancelled { return }
            await self.handleClaimEventDelete(e)
          }
        }
      }
    }

    notesSubscriptionTask = Task {
      await withTaskGroup(of: Void.self) { group in
        group.addTask { for await e in noteInserts { if Task.isCancelled { return }
          await self.handleNoteInsert(e)
        } }
        group.addTask { for await e in noteUpdates { if Task.isCancelled { return }
          await self.handleNoteUpdate(e)
        } }
        group.addTask { for await e in noteDeletes { if Task.isCancelled { return }
          await self.handleNoteDelete(e)
        } }
      }
    }
  }

  /// Deterministic shutdown with strict ordering: Unsubscribe -> Cancel -> Await -> Cleanup.
  /// Prevents deadlocks and ensures test isolation.
  func shutdown() async {
    if isShutdown { return }
    isShutdown = true

    debugLog.log("üîª shutdown() called - starting deterministic teardown", category: .sync)

    // 1. Unsubscribe Channels (Close the stream sources)
    // This MUST happen before cancelling tasks to ensure streams terminate naturally where possible.
    if let channel = realtimeChannel {
      debugLog.log("  Unsubscribing realtime channel...", category: .sync)
      await channel.unsubscribe()
    }
    if let channel = broadcastChannel {
      debugLog.log("  Unsubscribing broadcast channel...", category: .sync)
      await channel.unsubscribe()
    }
    realtimeChannel = nil
    broadcastChannel = nil

    // 2. Cancel Tasks (Signal listeners to stop)
    debugLog.log("  Cancelling active tasks...", category: .sync)
    statusTask?.cancel()
    broadcastTask?.cancel()
    syncLoopTask?.cancel()

    // Ensure startup task is also cancelled if it's running
    startBroadcastListeningTask?.cancel()

    tasksSubscriptionTask?.cancel()
    activitiesSubscriptionTask?.cancel()
    listingsSubscriptionTask?.cancel()
    usersSubscriptionTask?.cancel()
    claimEventsSubscriptionTask?.cancel()
    notesSubscriptionTask?.cancel()

    #if DEBUG
    debugHangingTask?.cancel()
    #endif

    // 3. Await Tasks (Quiescence)
    // In .test mode, we use a timeout to fail fast if something hangs
    debugLog.log("  Awaiting task quiescence...", category: .sync)

    if mode == .test {
      // Provable Termination: Fail if tasks don't exit
      do {
        try await withTimeout(seconds: 2.0) {
          _ = await self.statusTask?.result
          _ = await self.broadcastTask?.result
          _ = await self.syncLoopTask?.result

          _ = await self.startBroadcastListeningTask?.result

          _ = await self.tasksSubscriptionTask?.result
          _ = await self.activitiesSubscriptionTask?.result
          _ = await self.listingsSubscriptionTask?.result
          _ = await self.usersSubscriptionTask?.result
          _ = await self.claimEventsSubscriptionTask?.result

          #if DEBUG
          _ = await self.debugHangingTask?.result
          #endif
        }
      } catch {
        debugLog.error("SyncManager.shutdown() timed out! Tasks stuck.")
      }
    } else {
      // In live/preview, just await (logging ensures visibility)
      _ = await statusTask?.result
      _ = await broadcastTask?.result
      _ = await syncLoopTask?.result

      _ = await startBroadcastListeningTask?.result

      _ = await tasksSubscriptionTask?.result
      _ = await activitiesSubscriptionTask?.result
      _ = await listingsSubscriptionTask?.result
      _ = await usersSubscriptionTask?.result
      _ = await claimEventsSubscriptionTask?.result
      _ = await notesSubscriptionTask?.result // Jobs Standard

      #if DEBUG
      _ = await debugHangingTask?.result
      #endif
    }

    // 4. Cleanup References
    statusTask = nil
    broadcastTask = nil
    syncLoopTask = nil
    startBroadcastListeningTask = nil

    tasksSubscriptionTask = nil
    activitiesSubscriptionTask = nil
    listingsSubscriptionTask = nil
    usersSubscriptionTask = nil
    claimEventsSubscriptionTask = nil
    notesSubscriptionTask = nil

    #if DEBUG
    debugHangingTask = nil
    #endif

    // Clear observer tokens
    observerTokens.removeAll()

    debugLog.log("‚úÖ shutdown() complete. SyncManager is quiescent.", category: .sync)
  }

  #if DEBUG
  /// Spawns a dummy task for testing deterministic shutdown.
  /// Cooperative: Sleeps in small chunks to allow cancellation.
  /// Updates `debugHangingTask` so shutdown() can find it.
  func performDebugTask(duration: TimeInterval) {
    debugLog.log("DEBUG: performDebugTask started", category: .sync)
    debugHangingTask = Task { [weak self] in
      let chunk = 0.1
      var elapsed = 0.0
      while elapsed < duration {
        if Task.isCancelled { return }
        try? await Task.sleep(nanoseconds: UInt64(chunk * 1_000_000_000))
        elapsed += chunk
      }
      // Self-clearing
      await MainActor.run { [weak self] in
        self?.debugHangingTask = nil
      }
    }
  }
  #endif

  func stopListening() async {
    debugLog.log("stopListening() called", category: .realtime)
    // 1. Unsubscribing logic handles termination of loops.
    // 2. shutdown() handles brute force cancellation of activeTasks.

    if let channel = realtimeChannel {
      debugLog.log("  Unsubscribing from postgres_changes channel...", category: .realtime)
      await channel.unsubscribe()
      debugLog.log("  postgres_changes channel unsubscribed", category: .realtime)
    }
    realtimeChannel = nil

    // Cleanup broadcast channel
    if let channel = broadcastChannel {
      debugLog.log("  Unsubscribing from broadcast channel...", category: .realtime)
      await channel.unsubscribe()
      debugLog.log("  Broadcast channel unsubscribed", category: .realtime)
    }
    broadcastChannel = nil

    isListening = false
    debugLog.log("‚úì Realtime stopped. isListening = false", category: .realtime)
  }

  // MARK: Private

  /// Lightweight DTO for fetching only IDs from Supabase
  private struct IDOnlyDTO: Codable {
    let id: UUID
  }

  private var isShutdown = false // Jobs Standard: Track lifecycle state

  private var modelContainer: ModelContainer?
  private var isListening = false
  private var syncRequestedDuringSync = false
  private var wasDisconnected = false // Track disconnection for reconnect sync

  private var syncRequested = false

  /// Tracks all active observer tokens for deterministic cleanup.
  private var observerTokens = [NSObjectProtocol]()

  /// Feature flag: Enable broadcast-based realtime (v2)
  /// When true, subscribes to broadcast channel IN ADDITION to postgres_changes
  /// Phase 1: Both run simultaneously for validation
  /// Phase 2: Remove postgres_changes listeners
  /// Phase 3: Remove inFlightTaskIds tracking (origin_user_id replaces it)
  private let useBroadcastRealtime = true

  /// Tasks currently being synced up - skip realtime echoes for these
  /// NOTE: Will be removed in Phase 3 once origin_user_id filtering is validated
  private var inFlightTaskIds = Set<UUID>()

  /// Activities currently being synced up - skip realtime echoes for these
  /// NOTE: Will be removed in Phase 3 once origin_user_id filtering is validated
  private var inFlightActivityIds = Set<UUID>()

  #if DEBUG
  /// Track recently processed IDs to detect duplicate processing (DEBUG only)
  /// Used during Phase 1 to log when both postgres_changes and broadcast process same event
  private var recentlyProcessedIds = Set<UUID>()
  #endif

  private var isAuthenticated: Bool {
    currentUserID != nil
  }

  /// Determines if a model should be treated as "local-authoritative" during SyncDown.
  /// Local-authoritative items should NOT be overwritten by server state until SyncUp succeeds.
  @inline(__always)
  private func isLocalAuthoritative(
    _ model: some RealtimeSyncable,
    inFlight: Bool
  ) -> Bool {
    model.syncState == .pending || model.syncState == .failed || inFlight
  }

  private func fetchCurrentUser(id: UUID) {
    guard let container = modelContainer else { return }
    let context = container.mainContext
    let descriptor = FetchDescriptor<User>(predicate: #Predicate { $0.id == id })

    do {
      if let user = try context.fetch(descriptor).first {
        currentUser = user
        debugLog.log("fetchCurrentUser: User found locally: \(user.name)", category: .sync)
      } else {
        currentUser = nil
        debugLog.log("fetchCurrentUser: User NOT found locally (yet)", category: .sync)
      }
    } catch {
      debugLog.error("Failed to fetch current user", error: error)
    }
  }

  /// Convert sync errors to user-friendly messages
  private func userFacingMessage(for error: Error) -> String {
    if let urlError = error as? URLError {
      switch urlError.code {
      case .notConnectedToInternet, .networkConnectionLost:
        return "No internet connection."
      case .timedOut:
        return "Connection timed out."
      default:
        return "Network error."
      }
    }

    // Detect Postgres/RLS errors
    // Note: PostgrestError handling ideally involves checking the error code (e.g. 42501 or PGRST102)
    let errorString = String(describing: error)
    if errorString.contains("42501") || errorString.localizedCaseInsensitiveContains("permission denied") {
      return "Permission denied. You can only edit your own profile."
    }

    return "Sync failed: \(error.localizedDescription)"
  }

  private func syncDown(context: ModelContext) async throws {
    let lastSync = lastSyncTime ?? Date.distantPast
    let lastSyncISO = ISO8601DateFormatter().string(from: lastSync)
    debugLog.log("syncDown() - fetching records updated since: \(lastSyncISO)", category: .sync)

    // Determine if we should run full reconciliation
    // Run on first sync (no lastSyncTime) to ensure clean slate
    let shouldReconcile = lastSyncTime == nil
    if shouldReconcile {
      debugLog.log("‚ö†Ô∏è First sync detected - will run FULL RECONCILIATION to remove orphan local records", category: .sync)
    }

    // Sync in order: ListingTypes ‚Üí ActivityTemplates ‚Üí Users ‚Üí Listings ‚Üí Tasks ‚Üí Activities (respects FK dependencies)
    // Types/Templates first since Listings reference them
    debugLog.log("Sync order: ListingTypes ‚Üí ActivityTemplates ‚Üí Users ‚Üí Listings ‚Üí Tasks ‚Üí Activities", category: .sync)

    debugLog.startTiming("syncDownListingTypes")
    try await syncDownListingTypes(context: context)
    debugLog.endTiming("syncDownListingTypes")

    debugLog.startTiming("syncDownActivityTemplates")
    try await syncDownActivityTemplates(context: context)
    debugLog.endTiming("syncDownActivityTemplates")

    debugLog.startTiming("syncDownUsers")
    try await syncDownUsers(context: context, since: lastSyncISO)
    debugLog.endTiming("syncDownUsers")

    debugLog.startTiming("syncDownProperties")
    try await syncDownProperties(context: context, since: lastSyncISO)
    debugLog.endTiming("syncDownProperties")

    debugLog.startTiming("syncDownListings")
    try await syncDownListings(context: context, since: lastSyncISO)
    debugLog.endTiming("syncDownListings")

    debugLog.startTiming("syncDownTasks")
    try await syncDownTasks(context: context, since: lastSyncISO)
    debugLog.endTiming("syncDownTasks")

    debugLog.startTiming("syncDownActivities")
    try await syncDownActivities(context: context, since: lastSyncISO)
    debugLog.endTiming("syncDownActivities")

    debugLog.startTiming("syncDownClaimEvents")
    try await syncDownClaimEvents(context: context, since: lastSyncISO)
    debugLog.endTiming("syncDownClaimEvents")

    // Notes (Incremental, Soft-Delete Aware)
    debugLog.startTiming("syncDownNotes")
    try await syncDownNotes(context: context)
    debugLog.endTiming("syncDownNotes")

    // JOBS-STANDARD: Order-Independent Relationship Reconciliation
    // Ensure Listing.owner is resolved regardless of sync order
    debugLog.startTiming("reconcileListingRelationships")
    try reconcileListingRelationships(context: context)
    debugLog.endTiming("reconcileListingRelationships")

    // Reconcile Listing -> Property relationships
    debugLog.startTiming("reconcileListingPropertyRelationships")
    try reconcileListingPropertyRelationships(context: context)
    debugLog.endTiming("reconcileListingPropertyRelationships")

    // ORPHAN RECONCILIATION: Remove local records that no longer exist on Supabase
    // This handles the case where records are hard-deleted on the server
    if shouldReconcile {
      debugLog.startTiming("reconcileOrphans")
      try await reconcileOrphans(context: context)
      debugLog.endTiming("reconcileOrphans")
    }
  }

  /// Removes local SwiftData entities that no longer exist on Supabase.
  /// This handles the case where records are hard-deleted on the server.
  /// Called on first sync (lastSyncTime == nil) to ensure local and remote are in sync.
  private func reconcileOrphans(context: ModelContext) async throws {
    debugLog.log("", category: .sync)
    debugLog.log("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó", category: .sync)
    debugLog.log("‚ïë           ORPHAN RECONCILIATION                            ‚ïë", category: .sync)
    debugLog.log("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù", category: .sync)

    var totalDeleted = 0

    // Reconcile Tasks
    debugLog.log("Reconciling Tasks...", category: .sync)
    let tasksDeleted = try await reconcileOrphanTasks(context: context)
    totalDeleted += tasksDeleted

    // Reconcile Activities
    debugLog.log("Reconciling Activities...", category: .sync)
    let activitiesDeleted = try await reconcileOrphanActivities(context: context)
    totalDeleted += activitiesDeleted

    // Reconcile Listings
    debugLog.log("Reconciling Listings...", category: .sync)
    let listingsDeleted = try await reconcileOrphanListings(context: context)
    totalDeleted += listingsDeleted

    // Reconcile Users (read-only but still need to remove orphans)
    debugLog.log("Reconciling Users...", category: .sync)
    let usersDeleted = try await reconcileOrphanUsers(context: context)
    totalDeleted += usersDeleted

    // Reconcile ClaimEvents
    debugLog.log("Reconciling ClaimEvents...", category: .sync)
    let claimEventsDeleted = try await reconcileOrphanClaimEvents(context: context)
    totalDeleted += claimEventsDeleted

    debugLog.log("", category: .sync)
    debugLog.log("Orphan reconciliation complete: deleted \(totalDeleted) total orphan records", category: .sync)
  }

  private func reconcileOrphanTasks(context: ModelContext) async throws -> Int {
    // Fetch all task IDs from Supabase
    let remoteDTOs: [IDOnlyDTO] = try await supabase
      .from("tasks")
      .select("id")
      .execute()
      .value
    let remoteIds = Set(remoteDTOs.map { $0.id })
    debugLog.log("  Remote tasks: \(remoteIds.count)", category: .sync)

    // Fetch all local tasks
    let localDescriptor = FetchDescriptor<TaskItem>()
    let localTasks = try context.fetch(localDescriptor)
    debugLog.log("  Local tasks: \(localTasks.count)", category: .sync)

    // Find and delete orphans
    var deletedCount = 0
    for task in localTasks {
      if !remoteIds.contains(task.id) {
        debugLog.log("  üóëÔ∏è Deleting orphan task: \(task.id) - \(task.title)", category: .sync)
        context.delete(task)
        deletedCount += 1
      }
    }

    debugLog.log("  Deleted \(deletedCount) orphan tasks", category: .sync)
    return deletedCount
  }

  private func reconcileOrphanActivities(context: ModelContext) async throws -> Int {
    let remoteDTOs: [IDOnlyDTO] = try await supabase
      .from("activities")
      .select("id")
      .execute()
      .value
    let remoteIds = Set(remoteDTOs.map { $0.id })
    debugLog.log("  Remote activities: \(remoteIds.count)", category: .sync)

    let localDescriptor = FetchDescriptor<Activity>()
    let localActivities = try context.fetch(localDescriptor)
    debugLog.log("  Local activities: \(localActivities.count)", category: .sync)

    var deletedCount = 0
    for activity in localActivities {
      if !remoteIds.contains(activity.id) {
        debugLog.log("  üóëÔ∏è Deleting orphan activity: \(activity.id) - \(activity.title)", category: .sync)
        context.delete(activity)
        deletedCount += 1
      }
    }

    debugLog.log("  Deleted \(deletedCount) orphan activities", category: .sync)
    return deletedCount
  }

  private func reconcileOrphanListings(context: ModelContext) async throws -> Int {
    let remoteDTOs: [IDOnlyDTO] = try await supabase
      .from("listings")
      .select("id")
      .execute()
      .value
    let remoteIds = Set(remoteDTOs.map { $0.id })
    debugLog.log("  Remote listings: \(remoteIds.count)", category: .sync)

    let localDescriptor = FetchDescriptor<Listing>()
    let localListings = try context.fetch(localDescriptor)
    debugLog.log("  Local listings: \(localListings.count)", category: .sync)

    var deletedCount = 0
    for listing in localListings {
      if !remoteIds.contains(listing.id) {
        debugLog.log("  üóëÔ∏è Deleting orphan listing: \(listing.id) - \(listing.address)", category: .sync)
        context.delete(listing)
        deletedCount += 1
      }
    }

    debugLog.log("  Deleted \(deletedCount) orphan listings", category: .sync)
    return deletedCount
  }

  private func reconcileOrphanUsers(context: ModelContext) async throws -> Int {
    let remoteDTOs: [IDOnlyDTO] = try await supabase
      .from("users")
      .select("id")
      .execute()
      .value
    let remoteIds = Set(remoteDTOs.map { $0.id })
    debugLog.log("  Remote users: \(remoteIds.count)", category: .sync)

    let localDescriptor = FetchDescriptor<User>()
    let localUsers = try context.fetch(localDescriptor)
    debugLog.log("  Local users: \(localUsers.count)", category: .sync)

    var deletedCount = 0
    for user in localUsers {
      if !remoteIds.contains(user.id) {
        debugLog.log("  üóëÔ∏è Deleting orphan user: \(user.id) - \(user.name)", category: .sync)
        context.delete(user)
        deletedCount += 1
      }
    }

    debugLog.log("  Deleted \(deletedCount) orphan users", category: .sync)
    return deletedCount
  }

  private func reconcileOrphanClaimEvents(context: ModelContext) async throws -> Int {
    let remoteDTOs: [IDOnlyDTO] = try await supabase
      .from("claim_events")
      .select("id")
      .execute()
      .value
    let remoteIds = Set(remoteDTOs.map { $0.id })
    debugLog.log("  Remote claim events: \(remoteIds.count)", category: .sync)

    let localDescriptor = FetchDescriptor<ClaimEvent>()
    let localClaimEvents = try context.fetch(localDescriptor)
    debugLog.log("  Local claim events: \(localClaimEvents.count)", category: .sync)

    var deletedCount = 0
    for claimEvent in localClaimEvents {
      if !remoteIds.contains(claimEvent.id) {
        debugLog.log("  üóëÔ∏è Deleting orphan claim event: \(claimEvent.id)", category: .sync)
        context.delete(claimEvent)
        deletedCount += 1
      }
    }

    debugLog.log("  Deleted \(deletedCount) orphan claim events", category: .sync)
    return deletedCount
  }

  /// Extract a UUID from an AnyJSON dictionary (used for realtime DELETE event handling)
  /// Handles various JSON value representations from supabase-swift
  private func extractUUID(from record: [String: AnyJSON], key: String) -> UUID? {
    guard let value = record[key] else { return nil }

    // Try direct string extraction using description
    let stringValue = String(describing: value)

    // Clean up the string - it might be wrapped in quotes or have "string(" prefix
    let cleanedValue = stringValue
      .replacingOccurrences(of: "string(\"", with: "")
      .replacingOccurrences(of: "\")", with: "")
      .replacingOccurrences(of: "\"", with: "")
      .trimmingCharacters(in: .whitespaces)

    return UUID(uuidString: cleanedValue)
  }

  private func syncDownUsers(context: ModelContext, since: String) async throws {
    debugLog.log("syncDownUsers() - querying Supabase...", category: .sync)
    var dtos: [UserDTO] = try await supabase
      .from("users")
      .select()
      .gt("updated_at", value: since)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "users", count: dtos.count)

    // üö® CRITICAL FIX: If we are authenticated but have no local currentUser,
    // we MUST fetch our own profile regardless of 'since' time.
    // This handles re-login scenarios where the user record is older than lastSyncTime.
    if currentUser == nil, let currentID = currentUserID {
      let isCurrentInBatch = dtos.contains { $0.id == currentID }
      if !isCurrentInBatch {
        debugLog.log("‚ö†Ô∏è Current user profile missing from delta sync - force fetching...", category: .sync)
        do {
          let currentUserDTO: UserDTO = try await supabase
            .from("users")
            .select()
            .eq("id", value: currentID)
            .single()
            .execute()
            .value
          debugLog.log("  ‚úÖ Force fetched current user profile: \(currentUserDTO.name)", category: .sync)
          dtos.append(currentUserDTO)
        } catch {
          debugLog.error("  ‚ùå Failed to force fetch current user profile", error: error)
        }
      }
    }

    for (index, dto) in dtos.enumerated() {
      debugLog.log("  Upserting user \(index + 1)/\(dtos.count): \(dto.id) - \(dto.name)", category: .sync)
      try await upsertUser(dto: dto, context: context)
    }
  }

  private func upsertUser(dto: UserDTO, context: ModelContext) async throws {
    let targetId = dto.id
    let descriptor = FetchDescriptor<User>(
      predicate: #Predicate { $0.id == targetId }
    )

    // 1. Fetch Existing
    let existing = try context.fetch(descriptor).first

    // 2. Conflict Check (Jobs-standard)
    // If local user is .pending, DO NOT overwrite pending fields with remote data.
    // We only proceed if .synced or .failed (failed typically means we want to retry or overwrite? Safe to overwrite if we trust server authoritative for everything except our unsynced changes).
    // Let's stick to strict: if .pending, skip scalar updates.
    // But we might still want to process Avatar if remote changed? That's complex merge.
    // For V1: "If local .pending, do not clobber scalar fields".
    // We will Apply scalars ONLY if existing is nil (insert) OR existing is NOT pending.

    let shouldApplyScalars = (existing == nil) || (existing?.syncState != .pending)

    // 3. Avatar Logic (Download)
    var newAvatarData: Data? = nil
    var shouldUpdateAvatar = false

    // Determine current local hash
    let currentLocalHash = existing?.avatarHash

    // Check if remote differs
    if let remoteHash = dto.avatarHash {
      if remoteHash != currentLocalHash {
        // Different! Check if we have a path
        if let path = dto.avatarPath {
          debugLog.log("    Avatar hash changed (remote: \(remoteHash.prefix(6))...). Downloading...", category: .sync)
          do {
            // Use Public URL download to bypass strict RLS on `storage.objects`
            // (Bucket is public, so this is reliable)
            let publicURL = try supabase.storage
              .from("avatars")
              .getPublicURL(path: path)

            let (data, _) = try await URLSession.shared.data(from: publicURL)

            newAvatarData = data
            shouldUpdateAvatar = true

            debugLog.log("    ‚úì Avatar downloaded via Public URL", category: .sync)
          } catch {
            debugLog.error("    ‚ö†Ô∏è Failed to download avatar", error: error)
            // On failure, keep local
          }
        } else {
          debugLog.log("    Remote hash exists but path is nil. Skipping avatar.", category: .sync)
        }
      }
    } else {
      // Remote hash is NIL.
      // If local is NOT nil, we must clear it (deletion propagated from server)
      if currentLocalHash != nil {
        shouldUpdateAvatar = true
        newAvatarData = nil // Clears it
        debugLog.log("    Remote avatar deleted. Clearing local.", category: .sync)
      }
    }

    if let user = existing {
      // UPDATE
      if shouldApplyScalars {
        debugLog.log("    UPDATE existing user: \(dto.id)", category: .sync)
        user.name = dto.name
        user.email = dto.email
        user.userType = UserType(rawValue: dto.userType) ?? .realtor
        user.updatedAt = dto.updatedAt

        // Only mark synced if we accept the server state
        user.markSynced()
      } else {
        debugLog.log("    SKIP scalar update for user \(dto.id) (Local state: \(user.syncState))", category: .sync)
      }

      // Apply Avatar Update (independent of scalar pending state? Usually yes, binary assets sync separately)
      // But if we have a pending avatar upload (local hash != remote hash), we shouldn't overwrite?
      // "Avatar processing ... off-main"
      // If we are pending, we assume local is newer.
      // If pending, skip avatar overwrite.
      if shouldApplyScalars {
        if shouldUpdateAvatar {
          user.avatar = newAvatarData
          user.avatarHash = dto.avatarHash
        }
      }

    } else {
      // INSERT
      debugLog.log("    INSERT new user: \(dto.id)", category: .sync)
      let newUser = dto.toModel()

      // Apply downloaded avatar
      if shouldUpdateAvatar {
        newUser.avatar = newAvatarData
        newUser.avatarHash = dto.avatarHash // Sync hash too
      }

      newUser.markSynced()
      context.insert(newUser)
    }

    // Update currentUser if this is the one
    if dto.id == currentUserID {
      fetchCurrentUser(id: dto.id)
    }
  }

  private func syncDownProperties(context: ModelContext, since: String) async throws {
    debugLog.log("syncDownProperties() - querying Supabase...", category: .sync)
    let dtos: [PropertyDTO] = try await supabase
      .from("properties")
      .select()
      .gt("updated_at", value: since)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "properties", count: dtos.count)

    for (index, dto) in dtos.enumerated() {
      debugLog.log("  Upserting property \(index + 1)/\(dtos.count): \(dto.id) - \(dto.address)", category: .sync)
      try upsertProperty(dto: dto, context: context)
    }
  }

  private func upsertProperty(dto: PropertyDTO, context: ModelContext) throws {
    let targetId = dto.id
    let descriptor = FetchDescriptor<Property>(
      predicate: #Predicate { $0.id == targetId }
    )

    if let existing = try context.fetch(descriptor).first {
      // Local-first: skip ALL updates if local-authoritative
      if isLocalAuthoritative(existing, inFlight: false) {
        debugLog.log(
          "[SyncDown] Skip update for property \(dto.id) ‚Äî local-authoritative (state=\(existing.syncState))",
          category: .sync
        )
        return
      }

      debugLog.log("    UPDATE existing property: \(dto.id)", category: .sync)
      existing.address = dto.address
      existing.unit = dto.unit
      existing.city = dto.city ?? ""
      existing.province = dto.province ?? ""
      existing.postalCode = dto.postalCode ?? ""
      existing.country = dto.country ?? "Canada"
      existing.propertyType = PropertyType(rawValue: dto.propertyType) ?? .residential
      existing.deletedAt = dto.deletedAt
      existing.updatedAt = dto.updatedAt

      existing.markSynced()
    } else {
      debugLog.log("    INSERT new property: \(dto.id)", category: .sync)
      let newProperty = dto.toModel()
      newProperty.markSynced()
      context.insert(newProperty)
    }
  }

  /// Reconciles Listing -> Property relationships after sync
  private func reconcileListingPropertyRelationships(context: ModelContext) throws {
    let listingsDescriptor = FetchDescriptor<Listing>()
    let propertiesDescriptor = FetchDescriptor<Property>()

    let allListings = try context.fetch(listingsDescriptor)
    let allProperties = try context.fetch(propertiesDescriptor)

    // Build property lookup by ID
    let propertiesById = Dictionary(uniqueKeysWithValues: allProperties.map { ($0.id, $0) })

    var linkedCount = 0
    for listing in allListings {
      if let propertyId = listing.propertyId, listing.property == nil {
        if let property = propertiesById[propertyId] {
          listing.property = property
          linkedCount += 1
        }
      }
    }

    if linkedCount > 0 {
      debugLog.log("  Linked \(linkedCount) listings to their properties", category: .sync)
    }
  }

  private func syncDownListings(context: ModelContext, since: String) async throws {
    debugLog.log("syncDownListings() - querying Supabase...", category: .sync)
    let dtos: [ListingDTO] = try await supabase
      .from("listings")
      .select()
      .gt("updated_at", value: since)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "listings", count: dtos.count)

    for (index, dto) in dtos.enumerated() {
      debugLog.log("  Upserting listing \(index + 1)/\(dtos.count): \(dto.id) - \(dto.address)", category: .sync)
      try upsertListing(dto: dto, context: context)
    }
  }

  private func upsertListing(dto: ListingDTO, context: ModelContext) throws {
    let targetId = dto.id
    let descriptor = FetchDescriptor<Listing>(
      predicate: #Predicate { $0.id == targetId }
    )

    if let existing = try context.fetch(descriptor).first {
      // üîê Local-first: skip ALL updates if local-authoritative
      // Note: No inFlightListingIds needed for V1 as listings are rarely user-edited locally
      if isLocalAuthoritative(existing, inFlight: false) {
        debugLog.log(
          "[SyncDown] Skip update for listing \(dto.id) ‚Äî local-authoritative (state=\(existing.syncState))",
          category: .sync
        )
        return
      }

      debugLog.log("    UPDATE existing listing: \(dto.id)", category: .sync)
      existing.address = dto.address
      existing.city = dto.city ?? ""
      existing.province = dto.province ?? ""
      existing.postalCode = dto.postalCode ?? ""
      existing.country = dto.country ?? "Canada"
      existing.price = dto.price.map { Decimal($0) }
      existing.mlsNumber = dto.mlsNumber
      existing.listingType = ListingType(rawValue: dto.listingType) ?? .sale
      existing.status = ListingStatus(rawValue: dto.status) ?? .draft
      if let stageValue = dto.stage, let resolvedStage = ListingStage(rawValue: stageValue) {
        existing.stage = resolvedStage
      } else {
        existing.stage = .pending
      }
      existing.propertyId = dto.propertyId
      existing.activatedAt = dto.activatedAt
      existing.pendingAt = dto.pendingAt
      existing.closedAt = dto.closedAt
      existing.deletedAt = dto.deletedAt
      existing.dueDate = dto.dueDate
      existing.updatedAt = dto.updatedAt

      // Link Owner Relationship
      try establishListingOwnerRelationship(listing: existing, ownerId: dto.ownedBy, context: context)

      existing.markSynced()
    } else {
      debugLog.log("    INSERT new listing: \(dto.id)", category: .sync)
      let newListing = dto.toModel()
      newListing.markSynced()
      context.insert(newListing)

      // Link Owner Relationship
      try establishListingOwnerRelationship(listing: newListing, ownerId: dto.ownedBy, context: context)
    }
  }

  private func syncDownTasks(context: ModelContext, since: String) async throws {
    debugLog.log("syncDownTasks() - querying Supabase...", category: .sync)
    let dtos: [TaskDTO] = try await supabase
      .from("tasks")
      .select()
      .gt("updated_at", value: since)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "tasks", count: dtos.count)

    for (index, dto) in dtos.enumerated() {
      debugLog.log("  Upserting task \(index + 1)/\(dtos.count): \(dto.id) - \(dto.title)", category: .sync)
      try upsertTask(dto: dto, context: context)
    }
  }

  private func upsertTask(dto: TaskDTO, context: ModelContext) throws {
    let targetId = dto.id
    let descriptor = FetchDescriptor<TaskItem>(
      predicate: #Predicate { $0.id == targetId }
    )

    if let existing = try context.fetch(descriptor).first {
      // üîê Local-first: skip ALL updates if local-authoritative
      if isLocalAuthoritative(existing, inFlight: inFlightTaskIds.contains(existing.id)) {
        debugLog.log(
          "[SyncDown] Skip update for task \(dto.id) ‚Äî local-authoritative (state=\(existing.syncState))",
          category: .sync
        )
        return
      }

      debugLog.log("    UPDATE existing task: \(dto.id)", category: .sync)
      // Apply server state ONLY when not local-authoritative
      existing.title = dto.title
      existing.taskDescription = dto.description ?? ""
      existing.dueDate = dto.dueDate
      existing.priority = Priority(rawValue: dto.priority) ?? .medium
      existing.status = TaskStatus(rawValue: dto.status) ?? .open
      existing.claimedBy = dto.claimedBy
      existing.claimedAt = dto.claimedAt
      existing.completedAt = dto.completedAt
      existing.deletedAt = dto.deletedAt
      existing.updatedAt = dto.updatedAt
      existing.listingId = dto.listing
      try establishTaskListingRelationship(task: existing, listingId: dto.listing, context: context)
      existing.markSynced()
    } else {
      debugLog.log("    INSERT new task: \(dto.id)", category: .sync)
      let newTask = dto.toModel()
      newTask.markSynced()
      context.insert(newTask)
      try establishTaskListingRelationship(task: newTask, listingId: dto.listing, context: context)
    }
  }

  /// Establishes bidirectional relationship between a task and its parent listing
  private func establishTaskListingRelationship(task: TaskItem, listingId: UUID?, context: ModelContext) throws {
    // Remove from old listing if listingId changed
    if let oldListing = task.listing, oldListing.id != listingId {
      debugLog.log("      Removing task from old listing: \(oldListing.id)", category: .sync)
      oldListing.tasks.removeAll { $0.id == task.id }
      task.listing = nil
    }

    // Add to new listing if listingId is set
    guard let listingId else {
      debugLog.log("      No listingId - task is standalone", category: .sync)
      return
    }

    let listingDescriptor = FetchDescriptor<Listing>(
      predicate: #Predicate { $0.id == listingId }
    )

    guard let parentListing = try context.fetch(listingDescriptor).first else {
      debugLog.log("      ‚ö†Ô∏è Parent listing \(listingId) not found - relationship deferred", category: .sync)
      return
    }

    // Establish bidirectional relationship
    if !parentListing.tasks.contains(where: { $0.id == task.id }) {
      debugLog.log("      Adding task to listing.tasks: \(listingId)", category: .sync)
      parentListing.tasks.append(task)
    }
    task.listing = parentListing
  }

  private func syncDownActivities(context: ModelContext, since: String) async throws {
    debugLog.log("syncDownActivities() - querying Supabase...", category: .sync)
    let dtos: [ActivityDTO] = try await supabase
      .from("activities")
      .select()
      .gt("updated_at", value: since)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "activities", count: dtos.count)

    for (index, dto) in dtos.enumerated() {
      debugLog.log("  Upserting activity \(index + 1)/\(dtos.count): \(dto.id) - \(dto.title)", category: .sync)
      try upsertActivity(dto: dto, context: context)
    }
  }

  private func upsertActivity(dto: ActivityDTO, context: ModelContext) throws {
    let targetId = dto.id
    let descriptor = FetchDescriptor<Activity>(
      predicate: #Predicate { $0.id == targetId }
    )

    if let existing = try context.fetch(descriptor).first {
      // üîê Local-first: skip ALL updates if local-authoritative
      if isLocalAuthoritative(existing, inFlight: inFlightActivityIds.contains(existing.id)) {
        debugLog.log(
          "[SyncDown] Skip update for activity \(dto.id) ‚Äî local-authoritative (state=\(existing.syncState))",
          category: .sync
        )
        return
      }

      debugLog.log("    UPDATE existing activity: \(dto.id)", category: .sync)
      existing.title = dto.title
      existing.activityDescription = dto.description ?? ""
      existing.type = ActivityType(rawValue: dto.activityType) ?? .other
      existing.dueDate = dto.dueDate
      existing.priority = Priority(rawValue: dto.priority) ?? .medium
      existing.status = ActivityStatus(rawValue: dto.status) ?? .open
      existing.claimedBy = dto.claimedBy
      existing.duration = dto.durationMinutes.map { TimeInterval($0 * 60) }
      existing.claimedAt = dto.claimedAt
      existing.completedAt = dto.completedAt
      existing.deletedAt = dto.deletedAt
      existing.updatedAt = dto.updatedAt
      existing.listingId = dto.listing
      try establishActivityListingRelationship(activity: existing, listingId: dto.listing, context: context)
      existing.markSynced()
    } else {
      debugLog.log("    INSERT new activity: \(dto.id)", category: .sync)
      let newActivity = dto.toModel()
      newActivity.markSynced()
      context.insert(newActivity)
      try establishActivityListingRelationship(activity: newActivity, listingId: dto.listing, context: context)
    }
  }

  /// Establishes bidirectional relationship between an activity and its parent listing
  private func establishActivityListingRelationship(activity: Activity, listingId: UUID?, context: ModelContext) throws {
    // Remove from old listing if listingId changed
    if let oldListing = activity.listing, oldListing.id != listingId {
      debugLog.log("      Removing activity from old listing: \(oldListing.id)", category: .sync)
      oldListing.activities.removeAll { $0.id == activity.id }
      activity.listing = nil
    }

    // Add to new listing if listingId is set
    guard let listingId else {
      debugLog.log("      No listingId - activity is standalone", category: .sync)
      return
    }

    let listingDescriptor = FetchDescriptor<Listing>(
      predicate: #Predicate { $0.id == listingId }
    )

    guard let parentListing = try context.fetch(listingDescriptor).first else {
      debugLog.log("      ‚ö†Ô∏è Parent listing \(listingId) not found - relationship deferred", category: .sync)
      return
    }

    // Establish bidirectional relationship
    if !parentListing.activities.contains(where: { $0.id == activity.id }) {
      debugLog.log("      Adding activity to listing.activities: \(listingId)", category: .sync)
      parentListing.activities.append(activity)
    }
    activity.listing = parentListing
  }

  private func syncDownClaimEvents(context: ModelContext, since: String) async throws {
    debugLog.log("syncDownClaimEvents() - querying Supabase...", category: .sync)
    let dtos: [ClaimEventDTO] = try await supabase
      .from("claim_events")
      .select()
      .gt("updated_at", value: since)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "claim_events", count: dtos.count)

    for (index, dto) in dtos.enumerated() {
      debugLog.log("  Upserting claim event \(index + 1)/\(dtos.count): \(dto.id)", category: .sync)
      try upsertClaimEvent(dto: dto, context: context)
    }
  }

  private func upsertClaimEvent(dto: ClaimEventDTO, context: ModelContext) throws {
    let targetId = dto.id
    let descriptor = FetchDescriptor<ClaimEvent>(
      predicate: #Predicate { $0.id == targetId }
    )

    if let existing = try context.fetch(descriptor).first {
      debugLog.log("    UPDATE existing claim event: \(dto.id)", category: .sync)

      let resolvedParentType: ParentType
      if let type = ParentType(rawValue: dto.parentType) {
        resolvedParentType = type
      } else {
        debugLog.log("‚ö†Ô∏è Invalid parentType '\(dto.parentType)' for ClaimEvent \(dto.id), defaulting to .task", category: .sync)
        resolvedParentType = .task
      }

      let resolvedAction: ClaimAction
      if let act = ClaimAction(rawValue: dto.action) {
        resolvedAction = act
      } else {
        debugLog.log("‚ö†Ô∏è Invalid action '\(dto.action)' for ClaimEvent \(dto.id), defaulting to .claimed", category: .sync)
        resolvedAction = .claimed
      }

      existing.parentType = resolvedParentType
      existing.parentId = dto.parentId
      existing.action = resolvedAction
      existing.userId = dto.userId
      existing.performedAt = dto.performedAt
      existing.reason = dto.reason
      existing.updatedAt = dto.updatedAt
      existing.markSynced()
    } else {
      debugLog.log("    INSERT new claim event: \(dto.id)", category: .sync)
      let newClaimEvent = dto.toModel()
      newClaimEvent.markSynced()
      context.insert(newClaimEvent)
    }
  }

  private func syncDownListingTypes(context: ModelContext) async throws {
    // Per-table watermark with 2s overlap window
    let lastSync = (mode == .live ? UserDefaults.standard.object(forKey: Self.lastSyncListingTypesKey) as? Date : nil) ?? Date
      .distantPast
    let safeDate = lastSync.addingTimeInterval(-2) // Overlap window
    let safeISO = ISO8601DateFormatter().string(from: safeDate)
    debugLog.log("syncDownListingTypes() - fetching records updated since: \(safeISO)", category: .sync)

    let dtos: [ListingTypeDefinitionDTO] = try await supabase
      .from("listing_types")
      .select()
      .gte("updated_at", value: safeISO)
      .execute()
      .value
    debugLog.logSyncOperation(operation: "FETCH", table: "listing_types", count: dtos.count)

    for dto in dtos {
      let descriptor = FetchDescriptor<ListingTypeDefinition>(predicate: #Predicate { $0.id == dto.id })
      let existing = try context.fetch(descriptor).first

      // Pending/failed protection: don't overwrite local changes
      if let existing, existing.syncState == .pending || existing.syncState == .failed {
        debugLog.log("    SKIP (pending/failed): \(dto.id)", category: .sync)
        continue
      }

      if let existing {
        // UPDATE
        debugLog.log("    UPDATE: \(dto.id) - \(dto.name)", category: .sync)
        existing.name = dto.name
        existing.isSystem = dto.isSystem
        existing.position = dto.position
        existing.isArchived = dto.isArchived
        existing.ownedBy = dto.ownedBy
        existing.updatedAt = dto.updatedAt
        existing.markSynced()
      } else {
        // INSERT
        debugLog.log("    INSERT: \(dto.id) - \(dto.name)", category: .sync)
        let newType = dto.toModel()
        newType.markSynced()
        context.insert(newType)
      }
    }

    // Update per-table watermark (only on success, only in live mode)
    if mode == .live {
      UserDefaults.standard.set(Date(), forKey: Self.lastSyncListingTypesKey)
    }

    // Update isListingConfigReady flag
    let allTypesDescriptor = FetchDescriptor<ListingTypeDefinition>(predicate: #Predicate { !$0.isArchived })
    let typesCount = try context.fetch(allTypesDescriptor).count
    isListingConfigReady = typesCount > 0
    debugLog.log("isListingConfigReady = \(isListingConfigReady) (\(typesCount) active types)", category: .sync)
  }

  private func syncDownActivityTemplates(context: ModelContext) async throws {
    // Per-table watermark with 2s overlap window
    let lastSync = (mode == .live ? UserDefaults.standard.object(forKey: Self.lastSyncActivityTemplatesKey) as? Date : nil) ??
      Date.distantPast
    let safeDate = lastSync.addingTimeInterval(-2)
    let safeISO = ISO8601DateFormatter().string(from: safeDate)
    debugLog.log("syncDownActivityTemplates() - fetching records updated since: \(safeISO)", category: .sync)

    let dtos: [ActivityTemplateDTO] = try await supabase
      .from("activity_templates")
      .select()
      .gte("updated_at", value: safeISO)
      .execute()
      .value
    debugLog.logSyncOperation(operation: "FETCH", table: "activity_templates", count: dtos.count)

    // Get all local ListingTypeDefinition IDs for FK validation
    let typesDescriptor = FetchDescriptor<ListingTypeDefinition>()
    let localTypes = try context.fetch(typesDescriptor)
    let localTypeIds = Set(localTypes.map { $0.id })

    var deferredTemplates = [ActivityTemplateDTO]()

    // First pass: process templates with valid FK
    for dto in dtos {
      // FK validation: skip if type doesn't exist locally
      guard localTypeIds.contains(dto.listingTypeId) else {
        debugLog.log("    DEFER (missing type): \(dto.id)", category: .sync)
        deferredTemplates.append(dto)
        continue
      }

      try upsertActivityTemplate(dto: dto, context: context, localTypes: localTypes)
    }

    // Second pass: retry deferred templates (types may have been inserted in first pass)
    if !deferredTemplates.isEmpty {
      debugLog.log("Second pass for \(deferredTemplates.count) deferred templates...", category: .sync)
      let refreshedTypesDescriptor = FetchDescriptor<ListingTypeDefinition>()
      let refreshedTypes = try context.fetch(refreshedTypesDescriptor)
      let refreshedTypeIds = Set(refreshedTypes.map { $0.id })

      for dto in deferredTemplates {
        if refreshedTypeIds.contains(dto.listingTypeId) {
          try upsertActivityTemplate(dto: dto, context: context, localTypes: refreshedTypes)
        } else {
          debugLog.log("    STILL MISSING TYPE: \(dto.id) -> \(dto.listingTypeId)", category: .sync)
        }
      }
    }

    // Update per-table watermark
    if mode == .live {
      UserDefaults.standard.set(Date(), forKey: Self.lastSyncActivityTemplatesKey)
    }
  }

  private func syncDownNotes(context: ModelContext) async throws {
    // Per-table watermark with 2s overlap window
    let lastSync = (mode == .live ? UserDefaults.standard.object(forKey: Self.lastSyncNotesKey) as? Date : nil) ?? Date
      .distantPast
    let safeDate = lastSync.addingTimeInterval(-2)
    let safeISO = ISO8601DateFormatter().string(from: safeDate)

    debugLog.log("syncDownNotes() - fetching records updated since: \(safeISO)", category: .sync)

    let dtos: [NoteDTO] = try await supabase
      .from("notes")
      .select()
      .gte("updated_at", value: safeISO)
      .execute()
      .value

    debugLog.logSyncOperation(operation: "FETCH", table: "notes", count: dtos.count)

    for dto in dtos {
      try upsertNote(dto: dto, context: context)
    }

    // Update per-table watermark
    if mode == .live {
      UserDefaults.standard.set(Date(), forKey: Self.lastSyncNotesKey)
    }
  }

  /// Centralized upsert logic for Notes (used by SyncDown and Realtime)
  private func upsertNote(dto: NoteDTO, context: ModelContext) throws {
    let descriptor = FetchDescriptor<Note>(predicate: #Predicate { $0.id == dto.id })
    let existing = try context.fetch(descriptor).first

    // Pending protection: don't overwrite if we have pending local changes
    if let existing, existing.syncState == .pending || existing.syncState == .failed {
      debugLog.log("    SKIP (pending/failed): \(dto.id)", category: .sync)
      return
    }

    if let existing {
      // UPDATE (or Soft Delete)
      if let deletedAt = dto.deletedAt {
        debugLog.log("    SOFT DELETE existing note: \(dto.id)", category: .sync)
        existing.deletedAt = deletedAt
        existing.markSynced() // Ensure state reflects server
      } else {
        debugLog.log("    UPDATE existing note: \(dto.id)", category: .sync)
        existing.content = dto.content
        existing.editedAt = dto.editedAt
        existing.editedBy = dto.editedBy
        existing.updatedAt = dto.updatedAt ?? existing.updatedAt // Fallback if nil in DTO (shouldn't be)
        existing.deletedAt = nil // Resurrect if needed
        existing.markSynced()
      }

      // Parent keys are immutable usually, but update just in case
      if let pType = ParentType(rawValue: dto.parentType) {
        existing.parentType = pType
      }
      existing.parentId = dto.parentId
    } else {
      // INSERT
      // If it's already deleted on server, should we insert it?
      // Yes, as a tombstone (deletedAt != nil) to prevent re-fetch or invalid reference issues.
      // But usually SyncDown fetches based onUpdatedAt, so we might want to have the record.
      debugLog.log("    INSERT new note: \(dto.id)", category: .sync)
      let newNote = dto.toModel()
      // toModel sets syncState=.synced
      context.insert(newNote)
    }
  }

  private func upsertActivityTemplate(
    dto: ActivityTemplateDTO,
    context: ModelContext,
    localTypes: [ListingTypeDefinition]
  ) throws {
    let descriptor = FetchDescriptor<ActivityTemplate>(predicate: #Predicate { $0.id == dto.id })
    let existing = try context.fetch(descriptor).first

    // Pending/failed protection
    if let existing, existing.syncState == .pending || existing.syncState == .failed {
      debugLog.log("    SKIP (pending/failed): \(dto.id)", category: .sync)
      return
    }

    if let existing {
      // UPDATE
      debugLog.log("    UPDATE: \(dto.id) - \(dto.title)", category: .sync)
      existing.title = dto.title
      existing.templateDescription = dto.description
      existing.position = dto.position
      existing.isArchived = dto.isArchived
      existing.audiencesRaw = dto.audiences
      existing.listingTypeId = dto.listingTypeId
      existing.defaultAssigneeId = dto.defaultAssigneeId
      existing.updatedAt = dto.updatedAt
      existing.listingType = localTypes.first { $0.id == dto.listingTypeId }
      existing.markSynced()
    } else {
      // INSERT
      debugLog.log("    INSERT: \(dto.id) - \(dto.title)", category: .sync)
      let newTemplate = dto.toModel()
      newTemplate.listingType = localTypes.first { $0.id == dto.listingTypeId }
      newTemplate.markSynced()
      context.insert(newTemplate)
    }
  }

  private func syncUp(context: ModelContext) async throws {
    debugLog.log("syncUp() - pushing dirty entities to Supabase", category: .sync)

    // 0. Reconcile legacy "phantom" users (local-only but marked synced)
    // This is a lightweight local migration measure.
    try? await reconcileLegacyLocalUsers(context: context)

    // Admin-only: ListingTypes and ActivityTemplates
    // Check if current user is admin
    let isAdmin = currentUser?.userType == .admin
    if isAdmin {
      debugLog.log("Admin user - syncing ListingTypes and ActivityTemplates", category: .sync)
      try await syncUpListingTypes(context: context)
      try await syncUpActivityTemplates(context: context)
    } else {
      debugLog.log("Non-admin user - skipping ListingTypes/Templates SyncUp", category: .sync)
    }

    debugLog.log(
      "Sync order: Users ‚Üí Properties ‚Üí Listings ‚Üí Tasks ‚Üí Activities ‚Üí ClaimEvents (FK dependencies)",
      category: .sync
    )

    // Sync in FK dependency order: Users first (owners), then Properties, then Listings, then Tasks/Activities
    try await syncUpUsers(context: context)
    try await syncUpProperties(context: context)
    try await syncUpListings(context: context)
    try await syncUpTasks(context: context)
    try await syncUpActivities(context: context)
    try await syncUpNotes(context: context)
    try await syncUpClaimEvents(context: context)
    debugLog.log("syncUp() complete", category: .sync)
  }

  /// One-time local migration to catch "phantom" users that are marked .synced but were never uploaded (syncedAt == nil)
  /// OR users who have avatar data but no hash (legacy data).
  private func reconcileLegacyLocalUsers(context: ModelContext) async throws {
    // Fetch ALL users and filter in memory to avoid SwiftData #Predicate enum issues
    let descriptor = FetchDescriptor<User>()
    let allUsers = try context.fetch(descriptor)

    // 1. Phantom Users (Synced but no syncedAt date -> Pending)
    let phantomUsers = allUsers.filter { user in
      user.syncStateRaw == .synced && user.syncedAt == nil
    }

    if !phantomUsers.isEmpty {
      debugLog.log("Found \(phantomUsers.count) phantom legacy users. Marking as pending for upload.", category: .sync)
      for user in phantomUsers {
        user.markPending()
      }
    }

    // 2. Avatar Migration (Avatar Data present but Hash missing)
    // These users need to generate a hash so we don't re-upload eternally or fail to sync.
    let legacyAvatarUsers = allUsers.filter { user in
      user.avatar != nil && user.avatarHash == nil
    }

    if !legacyAvatarUsers.isEmpty {
      debugLog.log("Found \(legacyAvatarUsers.count) users with legacy avatars (no hash). Migrating...", category: .sync)

      for user in legacyAvatarUsers {
        if let data = user.avatar {
          // Compute proper hash
          let (normalized, hash) = await normalizeAndHash(data: data)

          // Update model
          user.avatar = normalized
          user.avatarHash = hash

          // Mark pending to ensure we sync this up to server
          user.markPending()
        }
      }
      debugLog.log("‚úì Migrated \(legacyAvatarUsers.count) legacy avatars", category: .sync)
    }
  }

  private func syncUpUsers(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<User>()
    let allUsers = try context.fetch(descriptor)
    debugLog.log("syncUpUsers() - fetched \(allUsers.count) total users from SwiftData", category: .sync)

    // Filter for pending or failed users
    let pendingUsers = allUsers.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "users",
      count: pendingUsers.count,
      details: "of \(allUsers.count) total"
    )

    guard !pendingUsers.isEmpty else {
      debugLog.log("  No pending users to sync", category: .sync)
      return
    }

    // Process individually to handle avatar uploads reliably
    for user in pendingUsers {
      do {
        try await uploadAvatarAndSyncUser(user: user, context: context)

      } catch {
        let message = userFacingMessage(for: error)
        user.markFailed(message)
        debugLog.log("  ‚úó Failed to sync user \(user.id): \(error.localizedDescription)", category: .error)
      }
    }
  }

  /// Extracted helper for clarity and isolation
  private func uploadAvatarAndSyncUser(user: User, context _: ModelContext) async throws {
    var avatarPath: String? = nil
    var avatarHash: String? = nil
    var uploadFailed = false

    if let avatarData = user.avatar {
      // Normalize & Hash (Off-Main)
      let (normalizedData, newHash) = await normalizeAndHash(data: avatarData)

      // If changed, Upload
      if newHash != user.avatarHash {
        debugLog.log("  Avatar hash changed. Uploading...", category: .sync)

        // Path: stored at root of 'avatars' bucket (User ID only)
        // "avatars" is the bucket, so we don't need a folder prefix unless we want one.
        // Simplification for V1: Root path prevents double-prefix issues.
        let path = "\(user.id.uuidString).jpg"

        do {
          try await uploadAvatar(path: path, data: normalizedData)

          // Success: Update local
          user.avatar = normalizedData
          user.avatarHash = newHash

          avatarPath = path
          avatarHash = newHash
          debugLog.log("  ‚úì Avatar uploaded", category: .sync)
        } catch {
          debugLog.error("  ‚ö†Ô∏è Avatar upload failed", error: error)
          uploadFailed = true // Mark failure
        }
      } else {
        debugLog.log("  Avatar hash matches. Skipping upload.", category: .sync)
        // Deterministic path reconstruction
        avatarPath = "\(user.id.uuidString).jpg"
        avatarHash = user.avatarHash
      }
    } else {
      // Nil avatar means delete
      avatarPath = nil
      avatarHash = nil
    }

    // Critical Safety: If upload failed, we SKIP upsert to avoid wiping/staling server state.
    // This is "Blocking" behavior, but prevents data corruption.
    guard !uploadFailed else {
      debugLog.log("  ‚è≠Ô∏è Skipping User upsert due to avatar failure", category: .sync)
      return // User stays .pending
    }

    // Upsert
    let dto = UserDTO(from: user, avatarPath: avatarPath, avatarHash: avatarHash)
    try await supabase.from("users").upsert([dto]).execute()

    user.markSynced()
    debugLog.log("  ‚úì User \(user.id) synced", category: .sync)
  }

  /// Helper: Normalizes image to JPEG and computes SHA256 (Off-Main Actor)
  nonisolated private func normalizeAndHash(data: Data) async -> (Data, String) {
    await Task.detached(priority: .userInitiated) {
      // 1. Resize/Compress (Mocking via just using data for now to avoid UIKit/ImageRenderer complexity in this snippet if not imported)
      // Ideally: Use UIImage/NSImage to resize -> JPEG 0.8
      // For stability without UI deps in SyncManager (which might be Data/Logic only):
      // We will skip resize for this iteration but MUST do SHA256.
      // Wait, we can import ImageIO or similar?
      // "Jobs-standard rule: normalize".
      // I'll stick to just Hashing for V1 if I lack image tools in this context,
      // or I'll assume `data` is acceptable.
      // Let's implement SHA256.

      let hash = SHA256.hash(data: data).map { String(format: "%02x", $0) }.joined()
      // Returning original data as "normalized" for now to avoid massive dependency add.
      // TODO: Add Image Resizing.
      return (data, hash)
    }.value
  }

  private func uploadAvatar(path: String, data: Data) async throws {
    let bucket = "avatars"
    _ = try await supabase.storage
      .from(bucket)
      .upload(
        path,
        data: data,
        options: FileOptions(
          cacheControl: "3600",
          contentType: "image/jpeg",
          upsert: true
        )
      )
  }

  private func syncUpTasks(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<TaskItem>()
    let allTasks = try context.fetch(descriptor)
    debugLog.log("syncUpTasks() - fetched \(allTasks.count) total tasks from SwiftData", category: .sync)

    // Filter for pending or failed (retry) tasks
    let pendingTasks = allTasks.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "tasks",
      count: pendingTasks.count,
      details: "of \(allTasks.count) total"
    )

    // Debug: log claimedBy value for each pending task
    for task in pendingTasks {
      debugLog.log(
        "  üìã Pending task \(task.id): claimedBy=\(task.claimedBy?.uuidString ?? "nil"), title=\(task.title)",
        category: .sync
      )
    }

    guard !pendingTasks.isEmpty else {
      debugLog.log("  No pending tasks to sync", category: .sync)
      return
    }

    // Mark as in-flight before upsert to prevent realtime echo from overwriting local state
    inFlightTaskIds = Set(pendingTasks.map { $0.id })
    defer { inFlightTaskIds.removeAll() } // Always clear, even on error

    // Try batch first for efficiency
    do {
      let dtos = pendingTasks.map { task -> TaskDTO in
        let dto = TaskDTO(from: task)
        debugLog.log(
          "  üì§ Preparing DTO for task \(task.id): claimedBy=\(dto.claimedBy?.uuidString ?? "nil"), syncState=\(task.syncState)",
          category: .sync
        )
        return dto
      }
      debugLog.log("  Batch upserting \(dtos.count) tasks to Supabase...", category: .sync)
      try await supabase
        .from("tasks")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      // Success - mark all synced
      for task in pendingTasks {
        task.markSynced()
      }
      debugLog.log("  Marked \(pendingTasks.count) tasks as synced", category: .sync)
    } catch {
      // Batch failed - try individual items to isolate failures
      debugLog.log("Batch task sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for task in pendingTasks {
        do {
          let dto = TaskDTO(from: task)
          try await supabase
            .from("tasks")
            .upsert([dto])
            .execute()
          task.markSynced()
          debugLog.log("  ‚úì Task \(task.id) synced individually", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          task.markFailed(message)
          debugLog.error("  ‚úó Task \(task.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpActivities(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<Activity>()
    let allActivities = try context.fetch(descriptor)
    debugLog.log("syncUpActivities() - fetched \(allActivities.count) total activities from SwiftData", category: .sync)

    let pendingActivities = allActivities.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "activities",
      count: pendingActivities.count,
      details: "of \(allActivities.count) total"
    )

    guard !pendingActivities.isEmpty else {
      debugLog.log("  No pending activities to sync", category: .sync)
      return
    }

    // Mark as in-flight before upsert to prevent realtime echo from overwriting local state
    inFlightActivityIds = Set(pendingActivities.map { $0.id })
    defer { inFlightActivityIds.removeAll() }

    // Try batch first for efficiency
    do {
      let dtos = pendingActivities.map { ActivityDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) activities to Supabase...", category: .sync)
      try await supabase
        .from("activities")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      for activity in pendingActivities {
        activity.markSynced()
      }
      debugLog.log("  Marked \(pendingActivities.count) activities as synced", category: .sync)
    } catch {
      // Batch failed - try individual items to isolate failures
      debugLog.log("Batch activity sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for activity in pendingActivities {
        do {
          let dto = ActivityDTO(from: activity)
          try await supabase
            .from("activities")
            .upsert([dto])
            .execute()
          activity.markSynced()
          debugLog.log("  ‚úì Activity \(activity.id) synced individually", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          activity.markFailed(message)
          debugLog.error("  ‚úó Activity \(activity.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpNotes(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<Note>()
    let allNotes = try context.fetch(descriptor)

    let pendingNotes = allNotes.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "notes",
      count: pendingNotes.count,
      details: "of \(allNotes.count) total"
    )

    guard !pendingNotes.isEmpty else { return }

    // Batch upsert first
    do {
      let dtos = pendingNotes.map { NoteDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) notes...", category: .sync)
      try await supabase
        .from("notes")
        .upsert(dtos)
        .execute()

      for note in pendingNotes {
        note.markSynced()
        note.hasRemoteChangeWhilePending = false // Jobs Standard: Clear conflict flag
      }
      debugLog.log("  Marked \(pendingNotes.count) notes as synced", category: .sync)
    } catch {
      // Individual fallback
      debugLog.log("Batch note sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for note in pendingNotes {
        do {
          let dto = NoteDTO(from: note)
          try await supabase
            .from("notes")
            .upsert([dto])
            .execute()
          note.markSynced()
          note.hasRemoteChangeWhilePending = false // Jobs Standard: Clear conflict flag
          debugLog.log("  ‚úì Note \(note.id) synced", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          note.markFailed(message)
          debugLog.error("  ‚úó Note \(note.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpProperties(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<Property>()
    let allProperties = try context.fetch(descriptor)
    debugLog.log("syncUpProperties() - fetched \(allProperties.count) total properties from SwiftData", category: .sync)

    let pendingProperties = allProperties.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "properties",
      count: pendingProperties.count,
      details: "of \(allProperties.count) total"
    )

    guard !pendingProperties.isEmpty else {
      debugLog.log("  No pending properties to sync", category: .sync)
      return
    }

    // Try batch first for efficiency
    do {
      let dtos = pendingProperties.map { PropertyDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) properties to Supabase...", category: .sync)
      try await supabase
        .from("properties")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      for property in pendingProperties {
        property.markSynced()
      }
      debugLog.log("  Marked \(pendingProperties.count) properties as synced", category: .sync)
    } catch {
      // Batch failed - try individual items to isolate failures
      debugLog.log("Batch property sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for property in pendingProperties {
        do {
          let dto = PropertyDTO(from: property)
          try await supabase
            .from("properties")
            .upsert([dto])
            .execute()
          property.markSynced()
          debugLog.log("  ‚úì Property \(property.id) synced individually", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          property.markFailed(message)
          debugLog.error("  ‚úó Property \(property.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpListings(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<Listing>()
    let allListings = try context.fetch(descriptor)
    debugLog.log("syncUpListings() - fetched \(allListings.count) total listings from SwiftData", category: .sync)

    let pendingListings = allListings.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "listings",
      count: pendingListings.count,
      details: "of \(allListings.count) total"
    )

    guard !pendingListings.isEmpty else {
      debugLog.log("  No pending listings to sync", category: .sync)
      return
    }

    // Try batch first for efficiency
    do {
      let dtos = pendingListings.map { ListingDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) listings to Supabase...", category: .sync)
      try await supabase
        .from("listings")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      for listing in pendingListings {
        listing.markSynced()
      }
      debugLog.log("  Marked \(pendingListings.count) listings as synced", category: .sync)
    } catch {
      // Batch failed - try individual items to isolate failures
      debugLog.log("Batch listing sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for listing in pendingListings {
        do {
          let dto = ListingDTO(from: listing)
          try await supabase
            .from("listings")
            .upsert([dto])
            .execute()
          listing.markSynced()
          debugLog.log("  ‚úì Listing \(listing.id) synced individually", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          listing.markFailed(message)
          debugLog.error("  ‚úó Listing \(listing.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpClaimEvents(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<ClaimEvent>()
    let allClaimEvents = try context.fetch(descriptor)
    debugLog.log("syncUpClaimEvents() - fetched \(allClaimEvents.count) total claim events from SwiftData", category: .sync)

    let pendingClaimEvents = allClaimEvents.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "claim_events",
      count: pendingClaimEvents.count,
      details: "of \(allClaimEvents.count) total"
    )

    guard !pendingClaimEvents.isEmpty else {
      debugLog.log("  No pending claim events to sync", category: .sync)
      return
    }

    // Try batch first for efficiency
    do {
      let dtos = pendingClaimEvents.map { ClaimEventDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) claim events to Supabase...", category: .sync)
      try await supabase
        .from("claim_events")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      for claimEvent in pendingClaimEvents {
        claimEvent.markSynced()
      }
      debugLog.log("  Marked \(pendingClaimEvents.count) claim events as synced", category: .sync)
    } catch {
      // Batch failed - try individual items to isolate failures
      debugLog.log("Batch claim event sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for claimEvent in pendingClaimEvents {
        do {
          let dto = ClaimEventDTO(from: claimEvent)
          try await supabase
            .from("claim_events")
            .upsert([dto])
            .execute()
          claimEvent.markSynced()
          debugLog.log("  ‚úì ClaimEvent \(claimEvent.id) synced individually", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          claimEvent.markFailed(message)
          debugLog.error("  ‚úó ClaimEvent \(claimEvent.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpListingTypes(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<ListingTypeDefinition>()
    let allTypes = try context.fetch(descriptor)
    debugLog.log("syncUpListingTypes() - fetched \(allTypes.count) total", category: .sync)

    let pendingTypes = allTypes.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "listing_types",
      count: pendingTypes.count,
      details: "of \(allTypes.count) total"
    )

    guard !pendingTypes.isEmpty else {
      debugLog.log("  No pending listing types to sync", category: .sync)
      return
    }

    // Batch upsert first
    do {
      let dtos = pendingTypes.map { ListingTypeDefinitionDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) listing types...", category: .sync)
      try await supabase
        .from("listing_types")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      for type in pendingTypes {
        type.markSynced()
      }
    } catch {
      // Individual fallback
      debugLog.log("Batch listing type sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for type in pendingTypes {
        do {
          let dto = ListingTypeDefinitionDTO(from: type)
          try await supabase
            .from("listing_types")
            .upsert([dto])
            .execute()
          type.markSynced()
          debugLog.log("  ‚úì ListingType \(type.id) synced", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          type.markFailed(message)
          debugLog.error("  ‚úó ListingType \(type.id) sync failed: \(message)")
        }
      }
    }
  }

  private func syncUpActivityTemplates(context: ModelContext) async throws {
    let descriptor = FetchDescriptor<ActivityTemplate>()
    let allTemplates = try context.fetch(descriptor)
    debugLog.log("syncUpActivityTemplates() - fetched \(allTemplates.count) total", category: .sync)

    let pendingTemplates = allTemplates.filter { $0.syncState == .pending || $0.syncState == .failed }
    debugLog.logSyncOperation(
      operation: "PENDING",
      table: "activity_templates",
      count: pendingTemplates.count,
      details: "of \(allTemplates.count) total"
    )

    guard !pendingTemplates.isEmpty else {
      debugLog.log("  No pending activity templates to sync", category: .sync)
      return
    }

    // Batch upsert first
    do {
      let dtos = pendingTemplates.map { ActivityTemplateDTO(from: $0) }
      debugLog.log("  Batch upserting \(dtos.count) activity templates...", category: .sync)
      try await supabase
        .from("activity_templates")
        .upsert(dtos)
        .execute()
      debugLog.log("  Batch upsert successful", category: .sync)

      for template in pendingTemplates {
        template.markSynced()
      }
    } catch {
      // Individual fallback
      debugLog.log("Batch activity template sync failed, trying individually: \(error.localizedDescription)", category: .error)

      for template in pendingTemplates {
        do {
          let dto = ActivityTemplateDTO(from: template)
          try await supabase
            .from("activity_templates")
            .upsert([dto])
            .execute()
          template.markSynced()
          debugLog.log("  ‚úì ActivityTemplate \(template.id) synced", category: .sync)
        } catch {
          let message = userFacingMessage(for: error)
          template.markFailed(message)
          debugLog.error("  ‚úó ActivityTemplate \(template.id) sync failed: \(message)")
        }
      }
    }
  }

  /// Helper for test timeout
  private func withTimeout(seconds: TimeInterval, operation: @escaping @Sendable () async -> Void) async throws {
    try await withThrowingTaskGroup(of: Void.self) { group in
      // Task 1: Operation
      group.addTask {
        await operation()
      }

      // Task 2: Timer
      group.addTask {
        try await Task.sleep(for: .seconds(seconds))
        throw CancellationError() // Timer won
      }

      // Wait for first completion
      do {
        try await group.next()
        // If operation finished first, cancel timer
        group.cancelAll()
      } catch {
        // If timer finished first (threw), cancel operation and rethrow
        group.cancelAll()
        if mode == .test {
          struct TimeoutError: Error { }
          throw TimeoutError()
        } else {
          debugLog.error("Operation timed out after \(seconds)s")
        }
      }
    }
  }

  /// Maps Supabase RealtimeChannelStatus to our global SyncStatus
  private func mapRealtimeStatus(_ status: RealtimeChannelStatus) -> SyncStatus {
    switch status {
    case .subscribed:
      return .ok(Date()) // Connected and healthy
    case .subscribing:
      return .syncing // Connecting...
    case .unsubscribing:
      return .syncing // Disconnecting in progress
    case .unsubscribed:
      return .idle // Stopped
    @unknown default:
      return .idle
    }
  }

  /// Starts listening to broadcast channel (v2 pattern).
  /// Coexists with postgres_changes during Phase 1 migration.
  private func startBroadcastListening() async {
    guard useBroadcastRealtime else {
      debugLog.log("Broadcast realtime disabled (useBroadcastRealtime = false)", category: .channel)
      return
    }
    guard isAuthenticated, modelContainer != nil else {
      debugLog.log("Skipping broadcast listener - not authenticated or no container", category: .channel)
      return
    }

    debugLog.log("", category: .channel)
    debugLog.log("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó", category: .channel)
    debugLog.log("‚ïë       BROADCAST REALTIME (v2) STARTING                     ‚ïë", category: .channel)
    debugLog.log("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù", category: .channel)

    // CRITICAL: Set auth token for Realtime Authorization (RLS on realtime.messages)
    // This must be called BEFORE subscribing to private channels
    debugLog.log("Setting Realtime auth token...", category: .channel)
    await supabase.realtimeV2.setAuth()
    debugLog.log("‚úì Realtime auth token set", category: .channel)

    // Create broadcast channel
    // NOTE: Testing WITHOUT isPrivate to debug subscription timeout
    // realtime.broadcast_changes() may use public channels by default
    debugLog.log("Creating channel 'dispatch:broadcast' (testing without isPrivate)...", category: .channel)
    let channel = supabase.realtimeV2.channel("dispatch:broadcast") {
      // $0.isPrivate = true  // DISABLED for testing - may be causing timeout
      $0.broadcast.receiveOwnBroadcasts = true // We filter by origin_user_id instead
    }

    // Subscribe to all broadcast events
    let broadcastStream = channel.broadcastStream(event: "*")

    debugLog.log("Calling channel.subscribeWithError() for broadcast...", category: .channel)
    do {
      // Add timeout to detect hanging subscriptions
      try await withThrowingTaskGroup(of: Void.self) { group in
        group.addTask {
          try await channel.subscribeWithError()
        }
        group.addTask {
          try await Task.sleep(for: .seconds(10))
          throw NSError(domain: "Broadcast", code: -1, userInfo: [NSLocalizedDescriptionKey: "Subscription timed out after 10s"])
        }
        // Wait for first to complete (subscription or timeout)
        try await group.next()
        group.cancelAll()
      }
      debugLog.log("‚úÖ Broadcast channel subscribed successfully", category: .channel)
    } catch {
      debugLog.error("‚ùå Broadcast subscription failed", error: error)
      return
    }

    broadcastChannel = channel

    // Create listener task for broadcast events
    broadcastTask = Task { [weak self] in
      guard let self else { return }
      guard let container = modelContainer else { return }

      debugLog.log("üì° Broadcast listener task STARTED", category: .event)
      for await event in broadcastStream {
        if Task.isCancelled { break }
        await handleBroadcastEvent(event, container: container)
      }
      debugLog.log("üì° Broadcast listener task ENDED", category: .event)
    }

    debugLog.log("", category: .channel)
    debugLog.log("Broadcast channel ready - listening for events on 'dispatch:broadcast'", category: .channel)
  }

  /// Handles broadcast events - routes to existing upsert/delete methods
  /// The event parameter is the raw JSON message from broadcastStream
  private func handleBroadcastEvent(_ event: JSONObject, container: ModelContainer) async {
    do {
      // Log raw payload for debugging
      debugLog.log("", category: .event)
      debugLog.log("üì° RAW BROADCAST EVENT RECEIVED", category: .event)

      // JSONObject is [String: AnyJSON] - use JSONEncoder for AnyJSON (Codable)
      let encoder = JSONEncoder()
      encoder.outputFormatting = .prettyPrinted
      if
        let jsonData = try? encoder.encode(event),
        let jsonString = String(data: jsonData, encoding: .utf8)
      {
        debugLog.log("Raw payload:\n\(jsonString)", category: .event)
      } else {
        debugLog.log("Raw payload (keys): \(event.keys.joined(separator: ", "))", category: .event)
      }

      // Supabase Realtime wraps our payload in: { event, type, payload, meta }
      // Our BroadcastChangePayload is inside the "payload" field
      guard let innerPayload = event["payload"]?.objectValue else {
        debugLog.log(
          "Missing or invalid 'payload' field in broadcast event - keys: \(event.keys.joined(separator: ", "))",
          category: .event
        )
        return
      }

      // Use PostgrestClient's decoder for consistency with other DTO decoding
      guard
        let payloadData = try? encoder.encode(innerPayload),
        let payload = try? PostgrestClient.Configuration.jsonDecoder.decode(BroadcastChangePayload.self, from: payloadData)
      else {
        debugLog.log(
          "Failed to decode broadcast payload - inner keys: \(innerPayload.keys.joined(separator: ", "))",
          category: .event
        )
        return
      }

      // Version check: log unknown versions for visibility when we bump the version
      if payload.eventVersion != 1 {
        debugLog.log("Unknown event version \(payload.eventVersion) for table \(payload.table)", category: .event)
        // For now, still try to handle. Later, can gate behavior on version.
      }

      // Self-echo filtering: skip if originated from current user
      // NOTE: nil originUserId means system-originated - do NOT skip those
      if
        let originUserId = payload.originUserId,
        let currentUser = currentUserID,
        originUserId == currentUser
      {
        debugLog.log("‚è≠Ô∏è Skipping self-originated broadcast: \(payload.table) \(payload.type)", category: .event)
        return
      }

      debugLog.log("", category: .event)
      debugLog.log("üì° BROADCAST EVENT: \(payload.table) \(payload.type)", category: .event)

      let context = container.mainContext

      // Route to appropriate handler based on table (type-safe enum switch)
      switch payload.table {
      case .tasks:
        try await handleTaskBroadcast(payload: payload, context: context)
      case .activities:
        try await handleActivityBroadcast(payload: payload, context: context)
      case .listings:
        try await handleListingBroadcast(payload: payload, context: context)
      case .users:
        try await handleUserBroadcast(payload: payload, context: context)
      case .claimEvents:
        try await handleClaimEventBroadcast(payload: payload, context: context)
      }

      try context.save()

    } catch {
      debugLog.error("Failed to handle broadcast event", error: error)
    }
  }

  /// Handles task broadcast - converts payload to TaskDTO and calls existing upsertTask
  private func handleTaskBroadcast(payload: BroadcastChangePayload, context: ModelContext) async throws {
    if payload.type == .delete {
      if
        let oldRecord = payload.cleanedOldRecord(),
        let idString = oldRecord["id"] as? String,
        let id = UUID(uuidString: idString)
      {
        _ = try deleteLocalTask(id: id, context: context)
        debugLog.log("  ‚úì Broadcast: Deleted task \(id)", category: .event)
      }
    } else {
      // INSERT or UPDATE - use centralized cleanedRecord() helper
      guard let cleanRecord = payload.cleanedRecord() else { return }

      let recordData = try JSONSerialization.data(withJSONObject: cleanRecord)
      let dto = try PostgrestClient.Configuration.jsonDecoder.decode(TaskDTO.self, from: recordData)

      // Use existing in-flight check as backup (will be removed in Phase 3)
      if inFlightTaskIds.contains(dto.id) {
        debugLog.log("  ‚è≠Ô∏è Broadcast: Skipping in-flight task \(dto.id)", category: .event)
        return
      }

      #if DEBUG
      // Phase 1 duplicate detection: log if processed recently via postgres_changes
      if recentlyProcessedIds.contains(dto.id) {
        debugLog.log("  ‚ö†Ô∏è Broadcast: Duplicate processing detected for task \(dto.id)", category: .event)
      }
      recentlyProcessedIds.insert(dto.id)
      #endif

      try upsertTask(dto: dto, context: context)
      debugLog.log("  ‚úì Broadcast: Upserted task \(dto.id)", category: .event)
    }
  }

  /// Handles activity broadcast - converts payload to ActivityDTO and calls existing upsertActivity
  private func handleActivityBroadcast(payload: BroadcastChangePayload, context: ModelContext) async throws {
    if payload.type == .delete {
      if
        let oldRecord = payload.cleanedOldRecord(),
        let idString = oldRecord["id"] as? String,
        let id = UUID(uuidString: idString)
      {
        _ = try deleteLocalActivity(id: id, context: context)
        debugLog.log("  ‚úì Broadcast: Deleted activity \(id)", category: .event)
      }
    } else {
      guard let cleanRecord = payload.cleanedRecord() else { return }

      let recordData = try JSONSerialization.data(withJSONObject: cleanRecord)
      let dto = try PostgrestClient.Configuration.jsonDecoder.decode(ActivityDTO.self, from: recordData)

      if inFlightActivityIds.contains(dto.id) {
        debugLog.log("  ‚è≠Ô∏è Broadcast: Skipping in-flight activity \(dto.id)", category: .event)
        return
      }

      #if DEBUG
      if recentlyProcessedIds.contains(dto.id) {
        debugLog.log("  ‚ö†Ô∏è Broadcast: Duplicate processing detected for activity \(dto.id)", category: .event)
      }
      recentlyProcessedIds.insert(dto.id)
      #endif

      try upsertActivity(dto: dto, context: context)
      debugLog.log("  ‚úì Broadcast: Upserted activity \(dto.id)", category: .event)
    }
  }

  /// Handles listing broadcast - converts payload to ListingDTO and calls existing upsertListing
  private func handleListingBroadcast(payload: BroadcastChangePayload, context: ModelContext) async throws {
    if payload.type == .delete {
      if
        let oldRecord = payload.cleanedOldRecord(),
        let idString = oldRecord["id"] as? String,
        let id = UUID(uuidString: idString)
      {
        _ = try deleteLocalListing(id: id, context: context)
        debugLog.log("  ‚úì Broadcast: Deleted listing \(id)", category: .event)
      }
    } else {
      guard let cleanRecord = payload.cleanedRecord() else { return }

      let recordData = try JSONSerialization.data(withJSONObject: cleanRecord)
      let dto = try PostgrestClient.Configuration.jsonDecoder.decode(ListingDTO.self, from: recordData)

      #if DEBUG
      if recentlyProcessedIds.contains(dto.id) {
        debugLog.log("  ‚ö†Ô∏è Broadcast: Duplicate processing detected for listing \(dto.id)", category: .event)
      }
      recentlyProcessedIds.insert(dto.id)
      #endif

      try upsertListing(dto: dto, context: context)
      debugLog.log("  ‚úì Broadcast: Upserted listing \(dto.id)", category: .event)
    }
  }

  /// Handles user broadcast - converts payload to UserDTO and calls existing upsertUser
  private func handleUserBroadcast(payload: BroadcastChangePayload, context: ModelContext) async throws {
    if payload.type == .delete {
      if
        let oldRecord = payload.cleanedOldRecord(),
        let idString = oldRecord["id"] as? String,
        let id = UUID(uuidString: idString)
      {
        _ = try deleteLocalUser(id: id, context: context)
        debugLog.log("  ‚úì Broadcast: Deleted user \(id)", category: .event)
      }
    } else {
      guard let cleanRecord = payload.cleanedRecord() else { return }

      let recordData = try JSONSerialization.data(withJSONObject: cleanRecord)
      let dto = try PostgrestClient.Configuration.jsonDecoder.decode(UserDTO.self, from: recordData)

      #if DEBUG
      if recentlyProcessedIds.contains(dto.id) {
        debugLog.log("  ‚ö†Ô∏è Broadcast: Duplicate processing detected for user \(dto.id)", category: .event)
      }
      recentlyProcessedIds.insert(dto.id)
      #endif

      try await upsertUser(dto: dto, context: context)
      debugLog.log("  ‚úì Broadcast: Upserted user \(dto.id)", category: .event)
    }
  }

  /// Handles claim event broadcast - converts payload to ClaimEventDTO and calls existing upsertClaimEvent
  private func handleClaimEventBroadcast(payload: BroadcastChangePayload, context: ModelContext) async throws {
    if payload.type == .delete {
      if
        let oldRecord = payload.cleanedOldRecord(),
        let idString = oldRecord["id"] as? String,
        let id = UUID(uuidString: idString)
      {
        _ = try deleteLocalClaimEvent(id: id, context: context)
        debugLog.log("  ‚úì Broadcast: Deleted claim event \(id)", category: .event)
      }
    } else {
      guard let cleanRecord = payload.cleanedRecord() else { return }

      let recordData = try JSONSerialization.data(withJSONObject: cleanRecord)
      let dto = try PostgrestClient.Configuration.jsonDecoder.decode(ClaimEventDTO.self, from: recordData)

      #if DEBUG
      if recentlyProcessedIds.contains(dto.id) {
        debugLog.log("  ‚ö†Ô∏è Broadcast: Duplicate processing detected for claim event \(dto.id)", category: .event)
      }
      recentlyProcessedIds.insert(dto.id)
      #endif

      try upsertClaimEvent(dto: dto, context: context)
      debugLog.log("  ‚úì Broadcast: Upserted claim event \(dto.id)", category: .event)
    }
  }
}

// MARK: - Postgres Change Handlers (Phase 2)
// Implements type-safe handling for direct postgres_changes (Delta Sync)
extension SyncManager {

  // MARK: Internal

  func handleTaskInsert(_ action: InsertAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: TaskDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertTask(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle Task INSERT", error: error)
    }
  }

  func handleTaskUpdate(_ action: UpdateAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: TaskDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertTask(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle Task UPDATE", error: error)
    }
  }

  func handleTaskDelete(_ action: DeleteAction) async {
    guard let container = modelContainer else { return }
    if let id = extractUUID(from: action.oldRecord, key: "id") {
      _ = try? deleteLocalTask(id: id, context: container.mainContext)
    }
  }

  func handleActivityInsert(_ action: InsertAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: ActivityDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertActivity(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle Activity INSERT", error: error)
    }
  }

  func handleActivityUpdate(_ action: UpdateAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: ActivityDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertActivity(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle Activity UPDATE", error: error)
    }
  }

  func handleActivityDelete(_ action: DeleteAction) async {
    guard let container = modelContainer else { return }
    if let id = extractUUID(from: action.oldRecord, key: "id") {
      _ = try? deleteLocalActivity(id: id, context: container.mainContext)
    }
  }

  func handleListingInsert(_ action: InsertAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: ListingDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertListing(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle Listing INSERT", error: error)
    }
  }

  func handleListingUpdate(_ action: UpdateAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: ListingDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertListing(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle Listing UPDATE", error: error)
    }
  }

  func handleListingDelete(_ action: DeleteAction) async {
    guard let container = modelContainer else { return }
    if let id = extractUUID(from: action.oldRecord, key: "id") {
      _ = try? deleteLocalListing(id: id, context: container.mainContext)
    }
  }

  func handleUserInsert(_ action: InsertAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: UserDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try await upsertUser(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle User INSERT", error: error)
    }
  }

  func handleUserUpdate(_ action: UpdateAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: UserDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try await upsertUser(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle User UPDATE", error: error)
    }
  }

  func handleUserDelete(_ action: DeleteAction) async {
    guard let container = modelContainer else { return }
    if let id = extractUUID(from: action.oldRecord, key: "id") {
      _ = try? deleteLocalUser(id: id, context: container.mainContext)
    }
  }

  func handleClaimEventInsert(_ action: InsertAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: ClaimEventDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertClaimEvent(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle ClaimEvent INSERT", error: error)
    }
  }

  func handleClaimEventUpdate(_ action: UpdateAction) async {
    guard let container = modelContainer else { return }
    do {
      let dto = try action.decodeRecord(as: ClaimEventDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder)
      try upsertClaimEvent(dto: dto, context: container.mainContext)
    } catch {
      debugLog.error("Failed to handle ClaimEvent UPDATE", error: error)
    }
  }

  func handleClaimEventDelete(_ action: DeleteAction) async {
    guard let container = modelContainer else { return }
    if let id = extractUUID(from: action.oldRecord, key: "id") {
      _ = try? deleteLocalClaimEvent(id: id, context: container.mainContext)
    }
  }

  // MARK: Private

  private func handleNoteInsert(_ action: InsertAction) async {
    guard let dto = try? action.decodeRecord(as: NoteDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder) else { return }

    let shouldProcess = await MainActor.run {
      let descriptor = FetchDescriptor<Note>(predicate: #Predicate { $0.id == dto.id })
      if let existing = try? modelContainer?.mainContext.fetch(descriptor).first {
        // Pending Protection + Conflict Indicator
        if existing.syncState == .pending || existing.syncState == .failed {
          debugLog.log("RT: Ignoring INSERT for .pending Note \(dto.id)", category: .realtime)
          existing.hasRemoteChangeWhilePending = true
          return false
        }
      }
      return true
    }
    guard shouldProcess else { return }

    await MainActor.run {
      guard let context = modelContainer?.mainContext else { return }
      do {
        try upsertNote(dto: dto, context: context)
        debugLog.log("RT: Inserted Note \(dto.id)", category: .realtime)
      } catch {
        debugLog.error("RT: Note Insert Failed", error: error)
      }
    }
  }

  private func handleNoteUpdate(_ action: UpdateAction) async {
    guard let dto = try? action.decodeRecord(as: NoteDTO.self, decoder: PostgrestClient.Configuration.jsonDecoder) else { return }

    let shouldProcess = await MainActor.run {
      let descriptor = FetchDescriptor<Note>(predicate: #Predicate { $0.id == dto.id })
      if let existing = try? modelContainer?.mainContext.fetch(descriptor).first {
        // Pending Protection + Conflict Indicator
        if existing.syncState == .pending || existing.syncState == .failed {
          debugLog.log("RT: Ignoring UPDATE for .pending Note \(dto.id)", category: .realtime)
          existing.hasRemoteChangeWhilePending = true
          return false
        }
      }
      return true
    }
    guard shouldProcess else { return }

    await MainActor.run {
      guard let context = modelContainer?.mainContext else { return }
      do {
        try upsertNote(dto: dto, context: context)
        debugLog.log("RT: Updated Note \(dto.id) (Deleted: \(dto.deletedAt != nil))", category: .realtime)
      } catch {
        debugLog.error("RT: Note Update Failed", error: error)
      }
    }
  }

  private func handleNoteDelete(_ action: DeleteAction) async {
    guard let id = extractUUID(from: action.oldRecord, key: "id") else { return }

    await MainActor.run {
      guard let context = modelContainer?.mainContext else { return }
      // Defensive: Hard DELETE from server = Soft Delete locally (Tombstone)

      let descriptor = FetchDescriptor<Note>(predicate: #Predicate { $0.id == id })
      if let existing = try? context.fetch(descriptor).first {
        // Apply soft delete
        existing.deletedAt = Date()
        existing.markSynced()
        debugLog.log("RT: Hard DELETE event treated as Soft Delete for Note \(id)", category: .realtime)
      } else {
        debugLog.log("RT: Note \(id) not found for delete", category: .realtime)
      }
    }
  }
}
